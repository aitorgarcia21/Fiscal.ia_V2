import os
import json
from typing import List, Dict, Tuple
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage

# Imports pour les embeddings CGI
try:
    from mistral_cgi_embeddings import load_embeddings, search_similar_articles
    CGI_EMBEDDINGS_AVAILABLE = True
except ImportError:
    CGI_EMBEDDINGS_AVAILABLE = False

# Configuration
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")

# Initialisation du client Mistral
client = MistralClient(api_key=MISTRAL_API_KEY) if MISTRAL_API_KEY else None

def get_fiscal_response(query: str, conversation_history: List[Dict] = None) -> Tuple[str, List[str], float]:
    """Obtient une r√©ponse de l'assistant fiscal - VERSION OPTIMIS√âE AVEC EMBEDDINGS CGI."""
    all_sources_for_api = []
    confidence_score = 0.5 
    
    try:
        if not client:
            return "Erreur: Client Mistral non configur√©", [], 0.0
        
        # 1. √âTAPE: Recherche dans les embeddings CGI d'abord
        cgi_articles = []
        if CGI_EMBEDDINGS_AVAILABLE:
            try:
                cgi_articles = search_cgi_embeddings(query, max_results=2)
                if cgi_articles:
                    all_sources_for_api.extend([art.get('source', 'CGI') for art in cgi_articles])
                    confidence_score = 0.85  # Haute confiance avec CGI
            except Exception:
                pass  # Fallback silencieux
        
        # 2. √âTAPE: Construction du prompt avec ou sans CGI
        query_lower = query.lower()
        
        if cgi_articles:
            # Prompt enrichi avec vraies donn√©es CGI
            cgi_context = "\n\n".join([
                f"Source: {art['source']}\nContenu: {art['content']}"
                for art in cgi_articles
            ])
            
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Contexte CGI officiel:
---
{cgi_context}
---

Tu es un expert fiscal utilisant les donn√©es officielles du CGI. R√©ponds de mani√®re pr√©cise bas√©e sur ces sources, sans formatage markdown. Mentionne les articles CGI pertinents."""

        elif any(word in query_lower for word in ['tmi', 'tranche', 'marginal', 'imposition']):
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Tu es un expert fiscal fran√ßais sp√©cialis√© dans les TMI et bar√®mes fiscaux 2025. R√©ponds de mani√®re pr√©cise avec les vrais seuils officiels, sans formatage markdown. Calcule la TMI exacte si possible."""
            all_sources_for_api.append("Bar√®me fiscal 2025")
            confidence_score = 0.9
            
        elif any(word in query_lower for word in ['pea', 'plan', '√©pargne', 'actions']):
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Contexte: Le PEA permet d'investir jusqu'√† 150 000‚Ç¨ en actions europ√©ennes avec exon√©ration fiscale apr√®s 5 ans de d√©tention.

R√©ponds clairement et concr√®tement en tant qu'expert fiscal, sans formatage markdown."""
            all_sources_for_api.append("Code fiscal - PEA")
            confidence_score = 0.9
            
        elif any(word in query_lower for word in ['plus-value', 'immobilier', 'r√©sidence principale']):
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Contexte: La r√©sidence principale est exon√©r√©e de plus-values. Pour les autres biens immobiliers, il y a des abattements selon la dur√©e de d√©tention.

R√©ponds clairement et concr√®tement en tant qu'expert fiscal, sans formatage markdown."""
            all_sources_for_api.append("CGI - Plus-values immobili√®res")
            confidence_score = 0.9
            
        elif any(word in query_lower for word in ['micro', 'entrepreneur', 'r√©gime']):
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Contexte: Le r√©gime micro-entreprise permet de d√©clarer uniquement le chiffre d'affaires avec un abattement forfaitaire (34% pour les services, 71% pour la vente).

R√©ponds clairement et concr√®tement en tant qu'expert fiscal, sans formatage markdown."""
            all_sources_for_api.append("CGI - R√©gimes fiscaux")
            confidence_score = 0.9
            
        else:
            # R√©ponse g√©n√©rale rapide
            prompt = f"""Tu es Francis, assistant fiscal expert de Fiscal.ia.

Question: {query}

Tu es un expert fiscal fran√ßais. R√©ponds de mani√®re claire et pratique √† cette question fiscale, sans formatage markdown. Si tu as besoin de plus d'informations, demande des pr√©cisions sur la situation de l'utilisateur."""
            all_sources_for_api.append("Expertise Francis")
            confidence_score = 0.7

        # 3. √âTAPE: Appel Mistral
        messages = [ChatMessage(role="user", content=prompt)]
        
        chat_response = client.chat(
            model="mistral-large-latest",
            messages=messages,
            temperature=0.5,
            max_tokens=600
        )
        
        answer = chat_response.choices[0].message.content
        return answer, all_sources_for_api, confidence_score

    except Exception as e:
        # Fallback ultime pour Railway
        query_lower = query.lower()
        
        if 'tmi' in query_lower:
            return "Pour calculer votre TMI pr√©cise, j'ai besoin de conna√Ætre votre revenu annuel net imposable. Les tranches fiscales 2025 d√©terminent votre taux marginal selon votre situation. Quel est votre revenu annuel ?", ["Bar√®me 2025"], 0.8
        elif 'pea' in query_lower:
            return "Le PEA vous permet d'investir 150 000‚Ç¨ en actions europ√©ennes. Exon√©ration totale apr√®s 5 ans. Quels sont vos objectifs d'investissement ?", ["Code fiscal"], 0.8
        elif 'micro' in query_lower:
            return "En micro-entreprise, vous d√©clarez votre CA avec abattement automatique. Pour les services : 34%, pour la vente : 71%. Quel est votre secteur d'activit√© ?", ["R√©gimes fiscaux"], 0.8
        else:
            return f"Je suis Francis, votre expert fiscal. Pour vous donner une r√©ponse pr√©cise sur '{query}', pouvez-vous me dire votre situation (salari√©, entrepreneur, investisseur) ?", ["Expert Francis"], 0.6

def get_fiscal_response_stream(query: str, conversation_history: List[Dict] = None):
    """Version streaming ultra-simplifi√©e pour Railway."""
    try:
        # Statut initial
        yield json.dumps({
            "type": "status",
            "message": "üîç Francis analyse votre question...",
            "progress": 50
        }) + "\n"
        
        # Obtenir la r√©ponse normale
        answer, sources, confidence = get_fiscal_response(query, conversation_history)
        
        # Simuler un streaming rapide
        yield json.dumps({
            "type": "start_response",
            "message": "üí° R√©ponse de Francis",
            "progress": 80
        }) + "\n"
        
        # Envoyer la r√©ponse
        yield json.dumps({
            "type": "content",
            "content": answer,
            "progress": 95
        }) + "\n"
        
        # Finaliser
        yield json.dumps({
            "type": "complete",
            "sources": sources,
            "confidence": confidence,
            "progress": 100
        }) + "\n"
        
    except Exception as e:
        yield json.dumps({
            "type": "error",
            "message": f"Erreur: {str(e)[:100]}"
        }) + "\n"

def search_cgi_embeddings(query: str, max_results: int = 2) -> List[Dict]:
    """Recherche dans les embeddings CGI de mani√®re optimis√©e pour Railway."""
    if not CGI_EMBEDDINGS_AVAILABLE:
        return []
    
    try:
        # Chargement avec timeout court
        embeddings = load_embeddings()
        if not embeddings:
            return []
        
        # Recherche rapide
        similar_articles = search_similar_articles(query, embeddings, top_k=max_results)
        
        # Formatage simple pour Railway
        results = []
        for article_data in similar_articles[:max_results]:
            results.append({
                'content': article_data.get('text', '')[:1000],  # Limiter pour Railway
                'source': f"CGI Article {article_data.get('article_number', 'N/A')}",
                'article_id': article_data.get('article_number', 'N/A')
            })
        
        return results
    except Exception as e:
        # Fallback silencieux
        return []

def main():
    """Test principal pour d√©veloppement local."""
    query = "Quelle est ma TMI si je gagne 50000‚Ç¨ ?"
    answer, sources, confidence = get_fiscal_response(query)
    print(f"R√©ponse: {answer}")
    print(f"Sources: {sources}")
    print(f"Confiance: {confidence}")

if __name__ == "__main__":
    main() 