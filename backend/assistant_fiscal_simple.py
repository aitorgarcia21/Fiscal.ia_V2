import os
import json
from typing import List, Dict, Tuple, AsyncGenerator, Optional
import typing
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage

# Imports pour les embeddings CGI
try:
    from mistral_cgi_embeddings import load_embeddings, search_similar_articles
    from mistral_embeddings import search_similar_bofip_chunks
    CGI_EMBEDDINGS_AVAILABLE = True
    BOFIP_EMBEDDINGS_AVAILABLE = True
except ImportError:
    CGI_EMBEDDINGS_AVAILABLE = False
    BOFIP_EMBEDDINGS_AVAILABLE = False

# Configuration
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")

# Initialisation du client Mistral
client = MistralClient(api_key=MISTRAL_API_KEY) if MISTRAL_API_KEY else None

# Cache global pour √©viter de recharger les embeddings - CHARGEMENT √Ä LA DEMANDE
_embeddings_cache = None
_cache_loaded = False

# Sources officielles autoris√©es
OFFICIAL_SOURCES = {
    'CGI': ['cgi_chunks', 'CGI'],
    'BOFIP': ['bofip_chunks_text', 'bofip_embeddings', 'BOFIP']
}

def validate_official_source(source_info: Dict) -> bool:
    """Valide qu'une source est officielle (CGI ou BOFiP uniquement)."""
    if not source_info:
        return False
    
    source_type = source_info.get('type', '').upper()
    source_path = source_info.get('path', '')
    
    # V√©rifier si c'est une source CGI
    if source_type == 'CGI' or any(cgi_marker in source_path for cgi_marker in OFFICIAL_SOURCES['CGI']):
        return True
    
    # V√©rifier si c'est une source BOFiP
    if source_type == 'BOFIP' or any(bofip_marker in source_path for bofip_marker in OFFICIAL_SOURCES['BOFIP']):
        return True
    
    return False

def get_quick_answer(query: str) -> tuple[str, bool]:
    """Retourne toujours une r√©ponse vide pour forcer une recherche approfondie dans les sources officielles."""
    return "", False

def get_fiscal_response(query: str, conversation_history: List[Dict] = None, user_profile_context: Optional[Dict[str, typing.Any]] = None):
    """G√©n√®re une r√©ponse fiscale pr√©cise bas√©e EXCLUSIVEMENT sur le CGI et le BOFiP, en tenant compte du profil utilisateur si fourni."""
    try:
        # Initialisation du client Mistral
        client = MistralClient(api_key=MISTRAL_API_KEY) if MISTRAL_API_KEY else None
        if not client:
            return "Erreur: Cl√© API Mistral non configur√©e", [], 0.0
        
        official_sources = []
        context_from_sources = "" # Renomm√© pour clart√©
        
        # 1. Recherche dans le CGI (priorit√© absolue) - CHARGEMENT √Ä LA DEMANDE
        try:
            cgi_articles = search_cgi_embeddings(query, max_results=3)
            if cgi_articles:
                context_from_sources += "=== ARTICLES DU CODE G√âN√âRAL DES IMP√îTS (CGI) ===\n\n"
                for article in cgi_articles:
                    if validate_official_source({'type': 'CGI', 'path': 'cgi_chunks'}):
                        article_content = article['content']
                        article_source = article['source']
                        context_from_sources += f"{article_source}:\n{article_content}\n\n"
                        official_sources.append(article_source)
                context_from_sources += "\n" + "="*60 + "\n\n"
        except Exception as e:
            print(f"Erreur lors de la recherche CGI (non bloquante): {e}")
        
        # 2. Recherche dans le BOFiP (compl√©ment officiel)
        try:
            bofip_chunks = search_bofip_embeddings(query, max_results=3)
            if bofip_chunks:
                context_from_sources += "=== BULLETIN OFFICIEL DES FINANCES PUBLIQUES (BOFiP) ===\n\n"
                for chunk in bofip_chunks:
                    if validate_official_source({'type': 'BOFIP', 'path': 'bofip_chunks'}):
                        chunk_content = chunk.get('text', '')[:2000]
                        chunk_source = f"BOFiP - {chunk.get('file', 'Chunk N/A')}"
                        context_from_sources += f"{chunk_source}:\n{chunk_content}\n\n"
                        official_sources.append(chunk_source)
                context_from_sources += "\n" + "="*60 + "\n\n"
        except Exception as e:
            print(f"Erreur lors de la recherche BOFiP (non bloquante): {e}")
        
        if not context_from_sources:
            return ("Je ne trouve pas d'informations dans les sources officielles (CGI et BOFiP) disponibles pour r√©pondre √† votre question. "
                   "Cela peut √™tre d√ª √† un probl√®me de chargement des donn√©es. Pourriez-vous reformuler votre question ?"), [], 0.0
        
        # Construction du contexte utilisateur si fourni
        user_context_str = ""
        if user_profile_context:
            user_context_str += "\nCONTEXTE FISCAL DE L'UTILISATEUR (pour mieux cibler la r√©ponse dans les textes officiels) :\n"
            if user_profile_context.get('tmi') is not None:
                user_context_str += f"- TMI (Tranche Marginale d'Imposition) : {user_profile_context['tmi']}%\n"
            if user_profile_context.get('situation_familiale'):
                user_context_str += f"- Situation familiale : {user_profile_context['situation_familiale']}\n"
            if user_profile_context.get('nombre_enfants') is not None:
                user_context_str += f"- Nombre d'enfants √† charge : {user_profile_context['nombre_enfants']}\n"
            if user_profile_context.get('revenus_annuels') is not None:
                user_context_str += f"- Revenus annuels nets : {user_profile_context['revenus_annuels']} ‚Ç¨\n"
            if user_profile_context.get('charges_deductibles') is not None:
                user_context_str += f"- Charges d√©ductibles annuelles : {user_profile_context['charges_deductibles']} ‚Ç¨\n"
            if user_profile_context.get('residence_principale') is not None:
                user_context_str += f"- Propri√©taire r√©sidence principale : {'Oui' if user_profile_context['residence_principale'] else 'Non'}\n"
            if user_profile_context.get('residence_secondaire') is not None:
                user_context_str += f"- Propri√©taire r√©sidence secondaire : {'Oui' if user_profile_context['residence_secondaire'] else 'Non'}\n"
            user_context_str += "NE PAS MENTIONNER EXPLICITEMENT CES DONN√âES PERSONNELLES DANS LA R√âPONSE, MAIS LES UTILISER POUR INTERPR√âTER LA QUESTION.\n\n"

        system_message = """Tu es Francis, assistant fiscal expert bas√© EXCLUSIVEMENT sur les textes officiels fran√ßais.

R√àGLES STRICTES :
1. Tu ne dois r√©pondre qu'en te basant sur le Code G√©n√©ral des Imp√¥ts (CGI) et le BOFiP fournis ci-dessous.
2. Le contexte utilisateur fourni (si pr√©sent) t'aide √† mieux comprendre la question et √† cibler les articles pertinents, mais ta r√©ponse doit TOUJOURS se fonder sur les textes officiels.
3. Lorsque cela est pertinent et justifie directement ta r√©ponse, cite l'article du CGI ou la r√©f√©rence BOFiP exacte. Si ta r√©ponse est de nature g√©n√©rale et ne s'appuie pas sur un texte sp√©cifique pour √™tre comprise, une citation n'est pas n√©cessaire.
4. Si l'information n'est pas dans les sources fournies, ou si la question sort du cadre fiscal fran√ßais, dis-le clairement.
5. Utilise uniquement les textes officiels, jamais d'autres sources ou tes connaissances g√©n√©rales.
6. R√©ponds en fran√ßais de mani√®re claire, pr√©cise et concise.
7. JAMAIS de formatage markdown (pas de #, *, -, etc.) - utilise uniquement du texte simple.
8. Pour les calculs fiscaux (ex: nombre de parts), sois TR√àS pr√©cis et explique ta m√©thode bas√©e sur le CGI.
9. V√©rifie tes calculs avant de r√©pondre.
10. Structure ta r√©ponse avec des paragraphes simples, sans puces ni num√©rotation superflue.

SOURCES OFFICIELLES DISPONIBLES :
"""
        
        full_prompt = f"""{system_message}
{context_from_sources}
{user_context_str}QUESTION DE L'UTILISATEUR :
{query}

R√âPONSE (bas√©e UNIQUEMENT sur les sources officielles et le contexte utilisateur pour l'interpr√©tation) :
"""

        # Construire l'historique de conversation si disponible
        messages_for_api = []
        if conversation_history:
            # Inclure jusqu'√† 10 messages pr√©c√©dents pour un meilleur contexte
            for msg in conversation_history[-10:]:
                if msg.get('role') and msg.get('content'):
                    # Tronquer chaque message pour √©viter l'explosion des tokens
                    truncated_content = msg['content'][:400]
                    messages_for_api.append(ChatMessage(role=msg['role'], content=truncated_content))
        
        messages_for_api.append(ChatMessage(role="user", content=full_prompt))
        
        # Appel √† Mistral avec temp√©rature basse pour plus de pr√©cision
        response = client.chat(
            model="mistral-large-latest",
            messages=messages_for_api,
            temperature=0.1,  # Tr√®s faible pour privil√©gier la pr√©cision
            max_tokens=1000
        )
        
        answer = response.choices[0].message.content.strip()
        
        # Supprimer la logique d'ajout du disclaimer. Francis g√®re les citations.
        final_answer = answer
        
        # Score de confiance bas√© sur la qualit√© des sources officielles
        confidence_score = min(1.0, len(official_sources) / 2.0) if official_sources else 0.1 # Ajust√© pour √™tre plus sensible
        
        return final_answer, list(set(official_sources)), confidence_score
        
    except Exception as e:
        print(f"Erreur lors du traitement de la question get_fiscal_response: {e}")
        return ("Erreur lors de la consultation des sources officielles. "
               "Veuillez r√©essayer ou reformuler votre question."), [], 0.0

def search_bofip_embeddings(query: str, max_results: int = 3) -> List[Dict]:
    """Recherche dans les embeddings BOFiP (source officielle)."""
    if not BOFIP_EMBEDDINGS_AVAILABLE:
        return []
    
    try:
        return search_similar_bofip_chunks(query, top_k=max_results)
    except Exception as e:
        print(f"Erreur dans search_bofip_embeddings: {e}")
        return []

def search_cgi_embeddings(query: str, max_results: int = 3) -> List[Dict]:
    """Recherche intelligente dans les embeddings CGI UNIQUEMENT - CHARGEMENT √Ä LA DEMANDE."""
    global _embeddings_cache, _cache_loaded
    
    if not CGI_EMBEDDINGS_AVAILABLE:
        return []
    
    try:
        # Cache des embeddings - CHARGEMENT √Ä LA DEMANDE SEULEMENT
        if not _cache_loaded:
            print("‚è≥ Chargement des embeddings CGI √† la demande...")
            _embeddings_cache = load_embeddings()
            _cache_loaded = True
            print("‚úÖ Embeddings CGI charg√©s")
        
        if not _embeddings_cache:
            return []
        
        # Am√©lioration de la requ√™te pour plus de pr√©cision
        query_lower = query.lower().strip()
        
        # ----------------------
        # D√©tection du sujet
        # ----------------------
        TOPIC_MAP = [
            {
                "match": ['tmi', 'tranche', 'marginal', 'imposition', 'bar√®me', 'imp√¥t sur le revenu', 'ir', 'imp√¥t', 'impots', 'payer', 'quotient', 'part'],
                "enhanced": "article 197 CGI imp√¥t sur le revenu bar√®me progressif tranches marginales taux imposition",
                "keywords": ['197', 'bar√®me', 'tranche', 'taux', 'imp√¥t', 'revenu', 'quotient', 'part']
            },
            {
                "match": ['tva', 'taxe valeur ajout√©e', 'taux tva'],
                "enhanced": "article 278 279 CGI TVA taux normal r√©duit super-r√©duit taxe valeur ajout√©e",
                "keywords": ['278', '279', 'tva', 'taux', 'taxe']
            },
            {
                "match": ['r√©duction', 'cr√©dit', 'd√©duction', 'avantage fiscal', 'credit d\'imp√¥t', 'cr√©dit d\'impot'],
                "enhanced": "article 199 200 CGI r√©duction cr√©dit imp√¥t d√©duction fiscale avantage",
                "keywords": ['199', '200', 'r√©duction', 'cr√©dit', 'd√©duction']
            },
            {
                "match": ['plus-value', 'plus value', 'cession', 'vente', 'pv', 'plusvalues'],
                "enhanced": "article 150 CGI plus-value cession vente immobilier actions",
                "keywords": ['150', 'plus-value', 'cession', 'vente']
            },
            {
                "match": ['sci', 'soci√©t√© civile', 'immobilier', 'sci familiale'],
                "enhanced": "CGI soci√©t√© civile immobili√®re SCI r√©gime fiscal imposition",
                "keywords": ['sci', 'soci√©t√©', 'civile', 'immobili√®re']
            },
            {
                "match": ['is', 'imp√¥t sur les soci√©t√©s', 'impot sur les societes', 'b√©n√©fice imposable', 'resultat fiscal'],
                "enhanced": "article 209 CGI imp√¥t sur les soci√©t√©s base imposable taux",
                "keywords": ['209', 'imp√¥t', 'soci√©t√©s', 'is', 'taux']
            },
            {
                "match": ['ifi', 'fortune', 'immobili√®re', 'imp√¥t sur la fortune immobili√®re'],
                "enhanced": "article 964 CGI imp√¥t sur la fortune immobili√®re assiette exon√©rations",
                "keywords": ['964', 'ifi', 'fortune', 'immobili√®re']
            },
            {
                "match": ['cvae', 'cfe', 'cotisation fonci√®re', 'cotisation sur la valeur ajout√©e'],
                "enhanced": "article 1586 CGI cfe cvae cotisation locale valeur ajout√©e entreprises",
                "keywords": ['1586', 'cfe', 'cvae', 'cotisation']
            }
        ]

        enhanced_query = None
        keywords = []
        for topic in TOPIC_MAP:
            if any(term in query_lower for term in topic["match"]):
                enhanced_query = topic["enhanced"]
                keywords = topic["keywords"]
                break

        # Fallback g√©n√©rique
        if enhanced_query is None:
            # Utiliser directement la requ√™te de l'utilisateur (sans pr√©fixe g√©n√©rique)
            enhanced_query = query  # Pas de pr√©fixe "CGI ..." pour √©viter un bruit inutile
            keywords = [word for word in query_lower.split() if len(word) > 3]
        
        # print(f"üîç Requ√™te de recherche am√©lior√©e : {enhanced_query}") # Supprim√© car trop verbeux
        
        # Recherche avec plus de r√©sultats pour filtrage
        similar_articles_raw = search_similar_articles(enhanced_query, _embeddings_cache, top_k=max_results * 4)
        
        # G√©rer le nouveau format √©ventuel (tuples) et pr√©server la similarit√©
        similar_articles = []
        for art in similar_articles_raw:
            if isinstance(art, tuple) and len(art) >= 2:
                article_data, sim_score = art[0], art[1]
                # Conserver la similarit√© pour le scoring
                article_data['similarity'] = sim_score
                similar_articles.append(article_data)
            else:
                similar_articles.append(art)
        
        # Scoring et filtrage avanc√© des r√©sultats AVEC validation des sources
        scored_articles = []
        for article_data in similar_articles[:max_results]:
            # VALIDATION STRICTE : V√©rifier que c'est bien du CGI
            if not validate_official_source({'type': 'CGI', 'path': 'cgi_chunks'}):
                continue  # Ignorer les sources non officielles
            
            content = article_data.get('text', '').lower()
            article_num = article_data.get('article_number', '')
            
            # Score bas√© sur la pr√©sence des mots-cl√©s
            keyword_score = sum(1 for keyword in keywords if keyword in content) / max(len(keywords), 1)
            
            # Score bonus si l'article est mentionn√© directement
            article_mention_score = 1.0 if f"article {article_num}" in query_lower else 0.0
            
            # Score combin√©
            similarity = getattr(article_data, 'similarity', 0.5)  # Fallback si pas de similarit√©
            final_score = (similarity * 0.7) + (keyword_score * 0.2) + (article_mention_score * 0.1)
            
            scored_articles.append({
                **article_data,
                'final_score': final_score
            })
        
        # Trier par score final et prendre les meilleurs
        scored_articles.sort(key=lambda x: x['final_score'], reverse=True)
        
        # Formatage des r√©sultats avec plus de contexte
        results = []
        for i, article_data in enumerate(scored_articles[:max_results]):
            # Pour les 3 premiers articles, prendre TOUT le texte
            if i < 3:
                text = article_data.get('text', '')  # Texte complet sans limitation
            else:
                # Pour les articles suivants, extraire la partie pertinente
                text = article_data.get('text', '')
                if len(text) > 3000:
                    # Chercher les paragraphes contenant les mots-cl√©s
                    paragraphs = text.split('\n')
                    relevant_paragraphs = []
                    for para in paragraphs:
                        if any(keyword in para.lower() for keyword in keywords):
                            relevant_paragraphs.append(para)
                    
                    if relevant_paragraphs:
                        text = '\n'.join(relevant_paragraphs[:5])[:3000]
                    else:
                        text = text[:3000]
            
            # print(f"üìÑ Article trouv√© : {article_data.get('article_number', 'N/A')} avec score {article_data.get('final_score', 0)}") # Supprim√© car trop verbeux
            results.append({
                'content': text,
                'source': f"CGI Article {article_data.get('article_number', 'N/A')}",
                'article_id': article_data.get('article_number', 'N/A')
            })
        
        return results
    except Exception as e:
        print(f"Erreur dans search_cgi_embeddings: {e}")
        return []  # Fallback silencieux

# Fonction de compatibilit√© pour l'ancien syst√®me
def get_relevant_context(query: str) -> str:
    """R√©cup√®re le contexte pertinent UNIQUEMENT depuis les sources officielles."""
    context = ""
    
    # Recherche CGI
    cgi_articles = search_cgi_embeddings(query, max_results=3)
    if cgi_articles:
        context += "=== CODE G√âN√âRAL DES IMP√îTS ===\n"
        for article in cgi_articles:
            context += f"{article['source']}: {article['content'][:1000]}...\n\n"
    
    # Recherche BOFiP
    bofip_chunks = search_bofip_embeddings(query, max_results=2)
    if bofip_chunks:
        context += "=== BULLETIN OFFICIEL DES FINANCES PUBLIQUES ===\n"
        for chunk in bofip_chunks:
            context += f"BOFiP: {chunk.get('text', '')[:1000]}...\n\n"
    
    return context if context else "Aucune source officielle trouv√©e pour cette question."

# NOUVELLE FONCTION STREAMING
async def get_fiscal_response_stream(query: str, conversation_history: List[Dict] = None, user_profile_context: Optional[Dict[str, typing.Any]] = None) -> AsyncGenerator[str, None]:
    """G√©n√®re une r√©ponse fiscale en streaming (actuellement, une seule r√©ponse compl√®te)."""
    try:
        answer, sources, confidence = get_fiscal_response(query, conversation_history, user_profile_context)
        
        response_data = {
            "type": "full_response",
            "answer": answer,
            "sources": sources,
            "confidence": confidence,
            "status": "success"
        }
        yield json.dumps(response_data) + "\n"
        
    except Exception as e:
        error_message = f"Erreur lors du traitement de la question en streaming: {str(e)}"
        print(error_message)
        error_response = {
            "type": "error",
            "message": error_message,
            "status": "error"
        }
        yield json.dumps(error_response) + "\n"

def main():
    """Test principal pour d√©veloppement local."""
    query = "Quelle est ma TMI si je gagne 50000‚Ç¨ ?"
    answer, sources, confidence = get_fiscal_response(query)
    print(f"R√©ponse: {answer}")
    print(f"Sources: {sources}")
    print(f"Confiance: {confidence}")

if __name__ == "__main__":
    main()
