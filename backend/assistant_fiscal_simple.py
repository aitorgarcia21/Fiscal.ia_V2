import os
import json
from typing import List, Dict, Tuple, AsyncGenerator, Optional, Literal
import typing

# Imports pour les embeddings CGI
try:
    from mistral_cgi_embeddings import load_embeddings, search_similar_articles
    from mistral_embeddings import search_similar_bofip_chunks
    CGI_EMBEDDINGS_AVAILABLE = True
    BOFIP_EMBEDDINGS_AVAILABLE = True
except ImportError:
    CGI_EMBEDDINGS_AVAILABLE = False
    BOFIP_EMBEDDINGS_AVAILABLE = False

# üìö SYST√àME MULTI-PROFILS VECTORIS√â
try:
    from multi_profile_search import multi_profile_search
    from profile_detector import profile_detector
    from knowledge_base_multi_profiles import ProfileType, RegimeFiscal, ThemeFiscal
    MULTI_PROFILE_AVAILABLE = True
    print("‚úÖ Syst√®me multi-profils charg√© avec succ√®s")
except ImportError as e:
    MULTI_PROFILE_AVAILABLE = False
    print(f"‚ö†Ô∏è Syst√®me multi-profils non disponible : {e}")

# Import des embeddings andorrans
try:
    from backend.mistral_andorra_embeddings import (
        search_similar_chunks as search_similar_andorra_chunks,
    )
    ANDORRA_EMBEDDINGS_AVAILABLE = True
except ImportError:
    # Fallback si le chemin absolu √©choue (ex√©cution depuis backend)
    try:
        from mistral_andorra_embeddings import (
            search_similar_chunks as search_similar_andorra_chunks,
        )
        ANDORRA_EMBEDDINGS_AVAILABLE = True
    except ImportError:
        ANDORRA_EMBEDDINGS_AVAILABLE = False

# Import des embeddings luxembourgeois
try:
    from backend.mistral_luxembourg_embeddings import (
        search_similar_chunks as search_similar_lux_chunks,
    )
    LUXEMBOURG_EMBEDDINGS_AVAILABLE = True
except ImportError:
    # Fallback si le chemin absolu √©choue (ex√©cution depuis backend)
    try:
        from mistral_luxembourg_embeddings import (
            search_similar_chunks as search_similar_lux_chunks,
        )
        LUXEMBOURG_EMBEDDINGS_AVAILABLE = True
    except ImportError:
        LUXEMBOURG_EMBEDDINGS_AVAILABLE = False

# Configuration
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")

# -----------------------------------------
# S√©lection dynamique du backend LLM
# -----------------------------------------
# Si LLM_ENDPOINT est d√©fini *ou* si la cl√© Mistral est absente,
# on bascule en mode local (Ollama ou proxy LiteLLM compatible).
USE_LOCAL_LLM = bool(os.getenv("LLM_ENDPOINT")) or not MISTRAL_API_KEY

if USE_LOCAL_LLM:
    # Client local (Ollama / LiteLLM proxy)
    from ollama_client import generate as _local_generate  # type: ignore
    ChatMessage = None  # Placeholder pour √©viter les r√©f√©rences inutiles
    client = None
else:
    # Client Mistral officiel
    from mistralai.client import MistralClient  # type: ignore
    from mistralai.models.chat_completion import ChatMessage  # type: ignore
    client = MistralClient(api_key=MISTRAL_API_KEY) if MISTRAL_API_KEY else None

# Cache global pour √©viter de recharger les embeddings - CHARGEMENT √Ä LA DEMANDE
_embeddings_cache = None
_cache_loaded = False

# Embeddings de base pour les questions essentielles (fallback)
BASE_EMBEDDINGS_FR = {
    "tmi": {
        "content": """Article 197 du CGI - Calcul de l'imp√¥t sur le revenu

L'imp√¥t sur le revenu est calcul√© en appliquant le bar√®me progressif aux revenus imposables.

Bar√®me de l'imp√¥t sur le revenu 2025 :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tranche de revenu imposable ‚îÇ Taux marginal (TMI)      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Jusqu'√† 11 497 ‚Ç¨           ‚îÇ 0%                       ‚îÇ
‚îÇ De 11 498 ‚Ç¨ √† 29 315 ‚Ç¨     ‚îÇ 11%                      ‚îÇ
‚îÇ De 29 316 ‚Ç¨ √† 83 823 ‚Ç¨     ‚îÇ 30%                      ‚îÇ
‚îÇ De 83 824 ‚Ç¨ √† 180 294 ‚Ç¨    ‚îÇ 41%                      ‚îÇ
‚îÇ Au-del√† de 180 294 ‚Ç¨       ‚îÇ 45%                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Le taux marginal d'imposition (TMI) correspond au taux de la tranche la plus √©lev√©e dans laquelle se situe le revenu imposable.

Exemples pratiques :
‚Ä¢ Revenu imposable de 30 000 ‚Ç¨ ‚Üí TMI de 30% (tranche de 29 316 ‚Ç¨ √† 83 823 ‚Ç¨)
‚Ä¢ Revenu imposable de 100 000 ‚Ç¨ ‚Üí TMI de 41% (tranche de 83 824 ‚Ç¨ √† 180 294 ‚Ç¨)
‚Ä¢ Revenu imposable de 200 000 ‚Ç¨ ‚Üí TMI de 45% (tranche au-del√† de 180 294 ‚Ç¨)""",
        "source": "CGI Article 197"
    },
    "tva": {
        "content": """Article 278 du CGI - Taxe sur la valeur ajout√©e

La TVA est un imp√¥t indirect sur la consommation. Les taux applicables sont :

- Taux normal : 20% (majorit√© des biens et services)
- Taux r√©duit : 10% (restauration, transports, travaux d'am√©lioration √©nerg√©tique)
- Taux r√©duit : 5,5% (produits alimentaires, livres, spectacles)
- Taux sp√©cial : 2,1% (m√©dicaments rembours√©s, presse)

La TVA est collect√©e par les entreprises et revers√©e √† l'√âtat.""",
        "source": "CGI Article 278"
    },
    "plus_value": {
        "content": """Article 150 du CGI - Plus-values immobili√®res

Les plus-values immobili√®res sont imposables selon les r√®gles suivantes :

- Calcul : Prix de vente - Prix d'achat - Frais
- Abattement : 6% par ann√©e de d√©tention (apr√®s 5 ans)
- Taux : 19% + 17,2% de pr√©l√®vements sociaux

Pour les plus-values mobili√®res :
- Abattement : 50% apr√®s 2 ans de d√©tention
- Taux : 12,8% + 17,2% de pr√©l√®vements sociaux""",
        "source": "CGI Article 150"
    }
}

# -----------------------------
# Embeddings de base Andorre
# -----------------------------

BASE_EMBEDDINGS_AD = {
    "irpf": {
        "content": """Llei 5/2014, article 83 ‚Äì Bar√®me de l'imp√¥t sur le revenu (IRPF)

Le bar√®me appliqu√© au revenu net imposable est le suivant (2025) :
‚Ä¢ 0 % jusqu'√† 24 000 ‚Ç¨
‚Ä¢ 5 % de 24 001 ‚Ç¨ √† 40 000 ‚Ç¨
‚Ä¢ 10 % au-del√† de 40 000 ‚Ç¨

Exemple : pour 55 000 ‚Ç¨, l'imp√¥t est 2 300 ‚Ç¨ :
0 ‚Ç¨ (‚â§ 24 000 ‚Ç¨) + 800 ‚Ç¨ (5 % de 16 000 ‚Ç¨) + 1 500 ‚Ç¨ (10 % de 15 000 ‚Ç¨).""",
        "source": "Llei 5/2014 ‚Äì Art. 83"
    },
    "igi": {
        "content": """Llei 11/2012, articles 47 √† 52 ‚Äì Impost General Indirecte (IGI)

Taux applicables :
‚Ä¢ 4,5 % g√©n√©ral
‚Ä¢ 1 % r√©duit (alimentation, sant√©, livres‚Ä¶)
‚Ä¢ 2,5 % sp√©cial restauration
‚Ä¢ 9,5 % major√© pour services financiers
‚Ä¢ 0 % exportations et secteurs exon√©r√©s.""",
        "source": "Llei 11/2012 ‚Äì Art. 47-52"
    }
}

# Sources officielles autoris√©es
OFFICIAL_SOURCES = {
    'CGI': ['cgi_chunks', 'CGI'],
    'BOFIP': ['bofip_chunks_text', 'bofip_embeddings', 'BOFIP']
}

def validate_official_source(source_info: Dict) -> bool:
    """Valide qu'une source est officielle (CGI ou BOFiP uniquement)."""
    if not source_info:
        return False
    
    source_type = source_info.get('type', '').upper()
    source_path = source_info.get('path', '')
    
    # V√©rifier si c'est une source CGI
    if source_type == 'CGI' or any(cgi_marker in source_path for cgi_marker in OFFICIAL_SOURCES['CGI']):
        return True
    
    # V√©rifier si c'est une source BOFiP
    if source_type == 'BOFIP' or any(bofip_marker in source_path for bofip_marker in OFFICIAL_SOURCES['BOFIP']):
        return True
    
    return False

def get_quick_answer(query: str) -> tuple[str, bool]:
    """Retourne toujours une r√©ponse vide pour forcer une recherche approfondie dans les sources officielles."""
    return "", False

def get_fiscal_response(query: str, conversation_history: List[Dict] = None, user_profile_context: Optional[Dict[str, typing.Any]] = None, jurisdiction: Literal["FR", "AD", "CH", "LU"] = "FR"):
    """
    G√©n√®re une r√©ponse fiscale en utilisant RAG avec les sources officielles.
    """
    if not client and not USE_LOCAL_LLM:
        return ("Service Mistral non disponible et aucun backend local d√©tect√©. Configurez MISTRAL_API_KEY ou LLM_ENDPOINT.", [], 0.0)
    
    # Construction du contexte utilisateur si fourni
    user_context_str = ""
    if user_profile_context:
        user_context_str = f"\n\nContexte utilisateur:\n{json.dumps(user_profile_context, indent=2, ensure_ascii=False)}"
    
    # Si juridiction = AD (Andorre), on utilise les embeddings andorrans
    if jurisdiction == "AD":
        context_from_sources = ""
        official_sources = []

        try:
            if ANDORRA_EMBEDDINGS_AVAILABLE:
                print(f"üîç Recherche Lois Andorranes pour: {query[:100]}...")
                andorra_chunks = search_similar_andorra_chunks(query, top_k=3)
                print(f"üìÑ Chunks Andorre trouv√©s: {len(andorra_chunks)}")

                if andorra_chunks:
                    context_from_sources += "=== L√âGISLATION FISCALE ANDORRANE ===\n\n"
                    for chunk in andorra_chunks:
                        chunk_content = chunk.get('text', '')[:2000]
                        chunk_source = chunk.get('file', 'Texte Andorran')
                        context_from_sources += f"{chunk_source}:\n{chunk_content}\n\n"
                        official_sources.append(chunk_source)
                    context_from_sources += "\n" + "="*60 + "\n\n"
                else:
                    print("‚ö†Ô∏è Aucun chunk Andorran trouv√©")
            else:
                print("‚ùå Embeddings Andorrans non disponibles")
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche Andorre: {e}")

    # Si juridiction = LU (Luxembourg), on utilise les embeddings de base Luxembourg
    elif jurisdiction == "LU":
        context_from_sources = ""
        official_sources = []
        
        # Tentative de r√©cup√©ration depuis les embeddings Luxembourg
        try:
            if LUXEMBOURG_EMBEDDINGS_AVAILABLE:
                print(f"üîç Recherche Lois Luxembourg pour: {query[:100]}...")
                lux_chunks = search_similar_lux_chunks(query, top_k=3)
                print(f"üìÑ Chunks Luxembourg trouv√©s: {len(lux_chunks)}")

                if lux_chunks:
                    context_from_sources += "=== L√âGISLATION FISCALE LUXEMBOURGEOISE ===\n\n"
                    for chunk in lux_chunks:
                        chunk_content = chunk.get('text', '')[:2000]
                        chunk_source = chunk.get('file', 'Texte Luxembourg')
                        context_from_sources += f"{chunk_source}:\n{chunk_content}\n\n"
                        official_sources.append(chunk_source)
                    context_from_sources += "\n" + "="*60 + "\n\n"
                else:
                    print("‚ö†Ô∏è Aucun chunk Luxembourg trouv√©")
            else:
                print("‚ùå Embeddings Luxembourg non disponibles")
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche Luxembourg: {e}")

        # Embeddings de base pour Luxembourg
        BASE_EMBEDDINGS_LU = {
            "ir": {
                "content": """Imp√¥t sur le revenu Luxembourg 2025

Le bar√®me progressif appliqu√© au revenu net imposable :
‚Ä¢ 0 % jusqu'√† 11 294 ‚Ç¨
‚Ä¢ 8 % de 11 295 ‚Ç¨ √† 19 932 ‚Ç¨  
‚Ä¢ 9 % de 19 933 ‚Ç¨ √† 28 032 ‚Ç¨
‚Ä¢ 10 % de 28 033 ‚Ç¨ √† 46 484 ‚Ç¨
‚Ä¢ 11 % de 46 485 ‚Ç¨ √† 100 002 ‚Ç¨
‚Ä¢ 12 % au-del√† de 100 002 ‚Ç¨

Le taux marginal d'imposition (TMI) correspond au taux de la tranche la plus √©lev√©e.""",
                "source": "Code fiscal luxembourgeois 2025"
            },
            "tva": {
                "content": """TVA Luxembourg 2025

Taux applicables :
‚Ä¢ 17 % taux normal (majorit√© des biens et services)
‚Ä¢ 14 % taux r√©duit (restauration, transports)
‚Ä¢ 8 % taux super-r√©duit (produits alimentaires, livres)
‚Ä¢ 3 % taux sp√©cial (m√©dicaments, presse)

La TVA est collect√©e par les entreprises et revers√©e √† l'√âtat.""",
                "source": "Code TVA luxembourgeois 2025"
            }
        }
        
        query_lower = query.lower()
        if any(term in query_lower for term in ['imp√¥t', 'impot', 'revenu', 'ir', 'bar√®me', 'tranche']):
            base = BASE_EMBEDDINGS_LU['ir']
            context_from_sources += "=== FISCALIT√â LUXEMBOURGEOISE ‚Äì IR ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])
        elif any(term in query_lower for term in ['tva', 'taxe', 'consommation']):
            base = BASE_EMBEDDINGS_LU['tva']
            context_from_sources += "=== FISCALIT√â LUXEMBOURGEOISE ‚Äì TVA ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])

    # Si juridiction = CH (Suisse), on utilise les embeddings suisses
    elif jurisdiction == "CH":
        context_from_sources = ""
        official_sources = []
        
        # Embeddings de base pour Suisse
        BASE_EMBEDDINGS_CH = {
            "ir": {
                "content": """Imp√¥t f√©d√©ral direct Suisse 2025

Le bar√®me progressif appliqu√© au revenu imposable :
‚Ä¢ 0 % jusqu'√† 14 500 CHF
‚Ä¢ 0,77 % de 14 501 CHF √† 31 600 CHF
‚Ä¢ 0,88 % de 31 601 CHF √† 41 400 CHF
‚Ä¢ 2,64 % de 41 401 CHF √† 55 200 CHF
‚Ä¢ 2,97 % de 55 201 CHF √† 267 600 CHF
‚Ä¢ 3,5 % de 267 601 CHF √† 725 400 CHF
‚Ä¢ 11,5 % au-del√† de 725 400 CHF

S'ajoutent les imp√¥ts cantonaux et communaux.""",
                "source": "Loi f√©d√©rale sur l'imp√¥t f√©d√©ral direct 2025"
            },
            "tva": {
                "content": """TVA Suisse 2025

Taux applicables :
‚Ä¢ 7,7 % taux normal (majorit√© des biens et services)
‚Ä¢ 2,5 % taux r√©duit (produits alimentaires, livres, m√©dicaments)
‚Ä¢ 3,7 % taux sp√©cial (h√©bergement touristique)

La TVA est collect√©e par les entreprises et revers√©e √† la Conf√©d√©ration.""",
                "source": "Loi f√©d√©rale sur la TVA 2025"
            }
        }
        
        query_lower = query.lower()
        if any(term in query_lower for term in ['imp√¥t', 'impot', 'revenu', 'f√©d√©ral', 'cantonal']):
            base = BASE_EMBEDDINGS_CH['ir']
            context_from_sources += "=== FISCALIT√â SUISSE ‚Äì IR ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])
        elif any(term in query_lower for term in ['tva', 'taxe', 'consommation']):
            base = BASE_EMBEDDINGS_CH['tva']
            context_from_sources += "=== FISCALIT√â SUISSE ‚Äì TVA ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])

    else:
        # France (FR) - logique enrichie avec syst√®me multi-profils
        context_from_sources = ""
        official_sources = []
        
        # üéØ D√âTECTION DE PROFIL UTILISATEUR
        profile_context = ""
        if MULTI_PROFILE_AVAILABLE:
            try:
                print(f"üîç D√©tection de profil pour: {query[:100]}...")
                profile_matches = profile_detector.detect_profile(query)
                
                if profile_matches:
                    best_match = profile_matches[0]
                    profile_type = best_match['profile']
                    confidence = best_match['confidence']
                    detected_keywords = best_match['detected_keywords']
                    
                    print(f"üë§ Profil d√©tect√©: {profile_type.value} (confiance: {confidence:.2f})")
                    print(f"üìù Mots-cl√©s: {detected_keywords}")
                    
                    # Recherche dans la base multi-profils
                    profile_results = multi_profile_search.search_knowledge(
                        query=query,
                        detected_profiles=profile_matches[:3],  # Top 3 profils
                        max_results=5
                    )
                    
                    if profile_results:
                        context_from_sources += "=== EXPERTISE FRANCIS - CONNAISSANCES SP√âCIALIS√âES ===\n\n"
                        for result in profile_results:
                            chunk = result['chunk']
                            score = result['weighted_score']
                            context_from_sources += f"üìã {chunk.profile.value} - {chunk.theme.value} (Score: {score:.3f})\n"
                            context_from_sources += f"{chunk.content}\n"
                            if chunk.examples:
                                context_from_sources += f"üí° Exemple: {chunk.examples[0]}\n"
                            context_from_sources += f"üîñ Tags: {', '.join(chunk.tags)}\n\n"
                            
                        official_sources.append("Expertise Francis - Base de connaissances multi-profils")
                        context_from_sources += "\n" + "="*60 + "\n\n"
                        
                        # Contexte pour le prompt
                        profile_context = f"\n\n=== CONTEXTE PROFIL UTILISATEUR ===\nProfil principal: {profile_type.value}\nConfiance: {confidence:.2f}\nMots-cl√©s d√©tect√©s: {', '.join(detected_keywords)}\n"
                    else:
                        print("‚ö†Ô∏è Aucun r√©sultat multi-profils trouv√©")
                else:
                    print("‚ö†Ô∏è Aucun profil d√©tect√©")
                    
            except Exception as e:
                print(f"‚ùå Erreur syst√®me multi-profils: {e}")

        # üìö RECHERCHE CGI (sources officielles)
        try:
            if CGI_EMBEDDINGS_AVAILABLE:
                print(f"üîç Recherche CGI pour: {query[:100]}...")
                cgi_chunks = search_cgi_embeddings(query, max_results=5)  # Augment√© √† 5
                print(f"üìÑ Chunks CGI trouv√©s: {len(cgi_chunks)}")

                if cgi_chunks:
                    context_from_sources += "=== CODE G√âN√âRAL DES IMP√îTS (CGI) ===\n\n"
                    for chunk in cgi_chunks:
                        chunk_content = chunk.get('content', '')[:3000]  # Augment√© √† 3000
                        chunk_source = chunk.get('source', 'CGI Article N/A')
                        context_from_sources += f"{chunk_source}:\n{chunk_content}\n\n"
                        official_sources.append(chunk_source)
                    context_from_sources += "\n" + "="*60 + "\n\n"
                else:
                    print("‚ö†Ô∏è Aucun chunk CGI trouv√©")
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche CGI: {e}")

        # 2. Recherche dans le BOFiP (compl√©ment officiel)
        try:
            if BOFIP_EMBEDDINGS_AVAILABLE:
                print(f"üîç Recherche BOFiP pour: {query[:100]}...")
                bofip_chunks = search_bofip_embeddings(query, max_results=3)
                print(f"üìÑ Chunks BOFiP trouv√©s: {len(bofip_chunks)}")

                if bofip_chunks:
                    context_from_sources += "=== BULLETIN OFFICIEL DES FINANCES PUBLIQUES (BOFiP) ===\n\n"
                    for chunk in bofip_chunks:
                        if validate_official_source({'type': 'BOFIP', 'path': 'bofip_chunks'}):
                            chunk_content = chunk.get('text', '')[:2000]
                            chunk_source = f"BOFiP - {chunk.get('file', 'Chunk N/A')}"
                            context_from_sources += f"{chunk_source}:\n{chunk_content}\n\n"
                            official_sources.append(chunk_source)
                    context_from_sources += "\n" + "="*60 + "\n\n"
                else:
                    print("‚ö†Ô∏è Aucun chunk BOFiP trouv√©")
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche BOFiP: {e}")
    
    # 3. Fallback vers les embeddings de base si aucune source trouv√©e
    if jurisdiction == "AD" and not context_from_sources:
        print("üîÑ Fallback Andorre simplifi√©‚Ä¶")
        query_lower = query.lower()
        if any(term in query_lower for term in ['irpf', 'imp√¥t sur le revenu', 'impot sur le revenu']):
            base = BASE_EMBEDDINGS_AD['irpf']
            context_from_sources += "=== FISCALIT√â ANDORRANE ‚Äì IRPF ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])
        elif any(term in query_lower for term in ['igi', 'tva', 'taxe', 'indirect']):
            base = BASE_EMBEDDINGS_AD['igi']
            context_from_sources += "=== FISCALIT√â ANDORRANE ‚Äì IGI ===\n\n" + f"{base['source']}:\n{base['content']}\n\n"
            official_sources.append(base['source'])

    if jurisdiction == "FR" and not context_from_sources:
        print("üîÑ Utilisation des embeddings de base...")
        query_lower = query.lower()
        if any(term in query_lower for term in ['tmi', 'taux marginal', 'tranche', 'imp√¥t', 'impot']):
            base_embedding = BASE_EMBEDDINGS_FR['tmi']
            context_from_sources += "=== CODE G√âN√âRAL DES IMP√îTS (CGI) ===\n\n"
            context_from_sources += f"{base_embedding['source']}:\n{base_embedding['content']}\n\n"
            official_sources.append(base_embedding['source'])
            context_from_sources += "\n" + "="*60 + "\n\n"
        elif any(term in query_lower for term in ['tva', 'taxe valeur ajout√©e']):
            base_embedding = BASE_EMBEDDINGS_FR['tva']
            context_from_sources += "=== CODE G√âN√âRAL DES IMP√îTS (CGI) ===\n\n"
            context_from_sources += f"{base_embedding['source']}:\n{base_embedding['content']}\n\n"
            official_sources.append(base_embedding['source'])
            context_from_sources += "\n" + "="*60 + "\n\n"
        elif any(term in query_lower for term in ['plus-value', 'plusvalue', 'plus value']):
            base_embedding = BASE_EMBEDDINGS_FR['plus_value']
            context_from_sources += "=== CODE G√âN√âRAL DES IMP√îTS (CGI) ===\n\n"
            context_from_sources += f"{base_embedding['source']}:\n{base_embedding['content']}\n\n"
            official_sources.append(base_embedding['source'])
            context_from_sources += "\n" + "="*60 + "\n\n"
    
    if not context_from_sources:
        # Fallback : r√©pondre tout de m√™me en mode "expert conseil" sans citation pr√©cise
        print(f"‚ö†Ô∏è Aucune source officielle trouv√©e pour : {query} ‚Äì utilisation du mode conseil g√©n√©rique")
        context_from_sources = "=== EXPERTISE FISCALE G√âN√âRALE ===\n\n" \
                             + "Les informations suivantes reposent sur les principes g√©n√©raux du droit fiscal fran√ßais, " \
                             + "les pratiques courantes de planification patrimoniale et l'exp√©rience de Francis en tant que conseiller CGP.\n\n"
    
    # Adapter le message syst√®me selon la juridiction
    if jurisdiction == "AD":
        system_message = """Tu es Francis, expert fiscal sp√©cialiste du droit fiscal andorran.

R√àGLES DE R√âPONSE :
1. Base-toi PRIORITAIREMENT sur les textes officiels andorrans fournis ci-dessous.
2. Si tu as des informations limit√©es mais pertinentes, donne des conseils g√©n√©raux bas√©s sur les principes fiscaux andorrans.
3. Pour les questions transfrontali√®res (France ‚Üî Andorre), explique les principes et conventions applicables.
4. Cite les sources (articles de loi, d√©crets) LORSQUE N√âCESSAIRE pour appuyer tes r√©ponses.
5. Utilise des TABLEAUX ASCII √©l√©gants (avec caract√®res ‚îå‚îê‚îî‚îò‚îú‚î§‚î¨‚î¥‚îº‚îÄ‚îÇ) pour pr√©senter bar√®mes, comparaisons et calculs de mani√®re claire et professionnelle.
6. Utilise ton expertise pour donner des conseils complets et pr√©cis bas√©s sur ta connaissance du droit fiscal andorran.
7. Sois toujours utile et informatif, m√™me avec des informations partielles.
8. R√©ponds en fran√ßais de mani√®re claire, structur√©e et professionnelle.
9. JAMAIS de formatage markdown (pas de #, *, -, etc.) - utilise uniquement du texte simple avec des puces ‚Ä¢ pour les listes.
10. Pour les calculs fiscaux, sois TR√àS pr√©cis et explique ta m√©thode avec des exemples chiffr√©s.
11. V√©rifie tes calculs avant de r√©pondre.
12. Structure ta r√©ponse avec des paragraphes clairs, des puces ‚Ä¢ pour les √©num√©rations, et commence toujours par "Bonjour".

SOURCES OFFICIELLES DISPONIBLES :
"""
    elif jurisdiction == "LU":
        system_message = """Tu es Francis, expert fiscal sp√©cialiste du droit fiscal luxembourgeois.

R√àGLES DE R√âPONSE :
1. Base-toi PRIORITAIREMENT sur les textes officiels luxembourgeois fournis ci-dessous.
2. Si tu as des informations limit√©es mais pertinentes, donne des conseils g√©n√©raux bas√©s sur les principes fiscaux luxembourgeois.
3. Pour les questions transfrontali√®res (France ‚Üî Luxembourg), explique les principes et conventions applicables.
4. Cite les sources (articles de loi, d√©crets) LORSQUE N√âCESSAIRE pour appuyer tes r√©ponses.
5. Utilise des TABLEAUX ASCII √©l√©gants (avec caract√®res ‚îå‚îê‚îî‚îò‚îú‚î§‚î¨‚î¥‚îº‚îÄ‚îÇ) pour pr√©senter bar√®mes, comparaisons et calculs de mani√®re claire et professionnelle.
6. Utilise ton expertise pour donner des conseils complets et pr√©cis bas√©s sur ta connaissance du droit fiscal luxembourgeois.
7. Sois toujours utile et informatif, m√™me avec des informations partielles.
8. R√©ponds en fran√ßais de mani√®re claire, structur√©e et professionnelle.
9. JAMAIS de formatage markdown (pas de #, *, -, etc.) - utilise uniquement du texte simple avec des puces ‚Ä¢ pour les listes.
10. Pour les calculs fiscaux, sois TR√àS pr√©cis et explique ta m√©thode avec des exemples chiffr√©s.
11. V√©rifie tes calculs avant de r√©pondre.
12. Structure ta r√©ponse avec des paragraphes clairs, des puces ‚Ä¢ pour les √©num√©rations, et commence toujours par "Bonjour".

SOURCES OFFICIELLES DISPONIBLES :
"""
    elif jurisdiction == "CH":
        system_message = """Tu es Francis, expert fiscal sp√©cialiste du droit fiscal suisse.

R√àGLES DE R√âPONSE :
1. Base-toi PRIORITAIREMENT sur les textes officiels suisses fournis ci-dessous.
2. Si tu as des informations limit√©es mais pertinentes, donne des conseils g√©n√©raux bas√©s sur les principes fiscaux suisses.
3. Pour les questions transfrontali√®res (France ‚Üî Suisse), explique les principes et conventions applicables.
4. Cite les sources (articles de loi, d√©crets) LORSQUE N√âCESSAIRE pour appuyer tes r√©ponses
5. Utilise des TABLEAUX ASCII √©l√©gants (avec caract√®res ‚îå‚îê‚îî‚îò‚îú‚î§‚î¨‚î¥‚îº‚îÄ‚îÇ) pour pr√©senter bar√®mes, comparaisons et calculs de mani√®re claire et professionnelle
6. Donne des r√©ponses DIRECTES et PRATIQUES - Jamais "je ne peux pas" ou "consultez un expert"
7. Utilise les donn√©es 2025 et ton expertise pour compl√©ter si n√©cessaire
8. Sois utile et informatif, toujours pr√™t √† aider
9. R√©ponds en fran√ßais de mani√®re claire et professionnelle
10. Format avec chiffres en gras et exemples concrets chiffr√©s
11. JAMAIS de formatage markdown (pas de #, *, -, etc.) - utilise uniquement du texte simple avec des puces ‚Ä¢ pour les listes
12. Pour les calculs fiscaux, sois TR√àS pr√©cis et explique ta m√©thode avec des exemples chiffr√©s
13. V√©rifie tes calculs avant de r√©pondre
14. Structure ta r√©ponse avec des paragraphes clairs, des puces ‚Ä¢ pour les √©num√©rations, et commence toujours par "Bonjour"

SOURCES OFFICIELLES DISPONIBLES :
"""
    else:
        # üéØ PROMPT ENRICHI AVEC CONTEXTE MULTI-PROFILS
        profile_instructions = ""
        if MULTI_PROFILE_AVAILABLE and profile_context:
            profile_instructions = f"""\n\nüéØ CONTEXTE UTILISATEUR D√âTECT√â :
{profile_context}

INSTRUCTIONS SP√âCIALIS√âES :
- Adapte ta r√©ponse au profil d√©tect√© (expertise pointue)
- Utilise les connaissances sp√©cialis√©es fournies dans les sources
- Donne des conseils concrets et actionnables pour ce profil
- Propose des optimisations sp√©cifiques au contexte identifi√©
- Cite les exemples pratiques quand disponibles"""
        
        system_message = f"""Tu es Francis, copilote fiscal et patrimonial ultra-sp√©cialis√© dans le droit fiscal fran√ßais.

üöÄ MISSION : Expert fiscal de r√©f√©rence pour les conseillers en gestion de patrimoine. Tes conseils constituent une expertise fiscale professionnelle compl√®te bas√©e sur :
‚Ä¢ Sources officielles (CGI, BOFiP)
‚Ä¢ Base de connaissances multi-profils sp√©cialis√©e
‚Ä¢ D√©tection intelligente du profil utilisateur
‚Ä¢ Exemples concrets et optimisations cibl√©es{profile_instructions}

R√àGLES DE R√âPONSE EXCELLENCE :
1. üìö Base-toi PRIORITAIREMENT sur les textes officiels du CGI et BOFiP fournis
2. üéØ Utilise les connaissances sp√©cialis√©es multi-profils pour enrichir ta r√©ponse
3. üí° Donne des conseils CONCRETS et ACTIONNABLES, jamais vagues
4. üìä Utilise des chiffres pr√©cis en gras et des exemples pratiques
5. üîç Cite les sources (articles CGI, BOFiP) pour appuyer tes r√©ponses
6. üìã Utilise des TABLEAUX pour pr√©senter bar√®mes, comparaisons, calculs
7. ‚ö° Compl√®te TOUJOURS avec ton expertise approfondie (ne jamais dire "pas d'info")
8. üé® Format professionnel fran√ßais, texte simple (JAMAIS de markdown)
9. üî¢ Calculs fiscaux ULTRA-PR√âCIS avec m√©thode d√©taill√©e
10. ‚úÖ V√©rifie tes calculs et coh√©rence avant r√©ponse
11. üèóÔ∏è Structure claire avec paragraphes simples
12. üíº Ton expertise = celle d'un expert-comptable + CGP senior combin√©s

SOURCES OFFICIELLES ET SP√âCIALIS√âES DISPONIBLES :
"""
        
    full_prompt = f"""{system_message}
{context_from_sources}
{user_context_str}QUESTION DE L'UTILISATEUR :
{query}

R√âPONSE (bas√©e UNIQUEMENT sur les sources officielles et le contexte utilisateur pour l'interpr√©tation) :
"""

    # Construire l'historique de conversation si disponible
    if USE_LOCAL_LLM:
        history_str = ""
        if conversation_history:
            for msg in conversation_history[-10:]:
                role = msg.get("role", "user").capitalize()
                content = msg.get("content", "")[:400]
                history_str += f"{role}: {content}\n"
        # Prompt final pour un mod√®le simple type chat-instruct
        local_prompt = (
            f"{history_str}Utilisateur: {full_prompt}\nAssistant:"  # On reste coh√©rent en fran√ßais
        )
        try:
            answer = _local_generate(
                local_prompt,
                model=os.getenv("LLM_LOCAL_MODEL", "mistral"),
                max_tokens=1000,
                temperature=0.1,
            ).strip()
        except Exception as e:
            # üîÑ Fallback automatique vers l'API Mistral si une cl√© est dispo
            if MISTRAL_API_KEY:
                try:
                    from mistralai.client import MistralClient  # type: ignore
                    from mistralai.models.chat_completion import ChatMessage as _ChatMessage  # type: ignore

                    _client_fallback = MistralClient(api_key=MISTRAL_API_KEY)
                    messages_fallback = [_ChatMessage(role="user", content=full_prompt)]
                    response_fb = _client_fallback.chat(
                        model="mistral-large-latest",
                        messages=messages_fallback,
                        temperature=0.1,
                        max_tokens=1000,
                    )
                    answer = response_fb.choices[0].message.content.strip()
                except Exception as e2:
                    return (f"Erreur LLM local puis fallback API Mistral : {e} / {e2}", [], 0.0)
            else:
                return (f"Erreur lors de l'appel au LLM local et aucune API Mistral disponible : {e}", [], 0.0)
    else:
        # --------------------
        # Appel API Mistral
        # --------------------
        messages_for_api = []
        if conversation_history and ChatMessage is not None:
            for msg in conversation_history[-10:]:
                if msg.get("role") and msg.get("content"):
                    truncated_content = msg["content"][:400]
                    messages_for_api.append(ChatMessage(role=msg["role"], content=truncated_content))

        if ChatMessage is not None:
            messages_for_api.append(ChatMessage(role="user", content=full_prompt))

        if not client:
            return ("Service Mistral non disponible. Configurez MISTRAL_API_KEY ou un LLM local.", [], 0.0)

        response = client.chat(
            model="mistral-large-latest",
            messages=messages_for_api,
            temperature=0.1,
            max_tokens=1000,
        )

        answer = response.choices[0].message.content.strip()

    # Supprimer la logique d'ajout du disclaimer. Francis g√®re les citations.
    final_answer = answer
    
    # Score de confiance bas√© sur la qualit√© des sources officielles
    confidence_score = min(1.0, len(official_sources) / 2.0) if official_sources else 0.1
    
    return final_answer, list(set(official_sources)), confidence_score

def search_bofip_embeddings(query: str, max_results: int = 3) -> List[Dict]:
    """Recherche dans les embeddings BOFiP (source officielle)."""
    if not BOFIP_EMBEDDINGS_AVAILABLE:
        return []
    
    try:
        return search_similar_bofip_chunks(query, top_k=max_results)
    except Exception as e:
        print(f"Erreur dans search_bofip_embeddings: {e}")
        return []

def search_cgi_embeddings(query: str, max_results: int = 3) -> List[Dict]:
    """Recherche intelligente dans les embeddings CGI UNIQUEMENT - CHARGEMENT √Ä LA DEMANDE."""
    global _embeddings_cache, _cache_loaded
    
    if not CGI_EMBEDDINGS_AVAILABLE:
        return []
    
    try:
        # Cache des embeddings - CHARGEMENT √Ä LA DEMANDE SEULEMENT
        if not _cache_loaded:
            print("‚è≥ Chargement des embeddings CGI √† la demande...")
            _embeddings_cache = load_embeddings()
            _cache_loaded = True
            print("‚úÖ Embeddings CGI charg√©s")
        
        if not _embeddings_cache:
            return []
        
        # Am√©lioration de la requ√™te pour plus de pr√©cision
        query_lower = query.lower().strip()
        
        # ----------------------
        # D√©tection du sujet
        # ----------------------
        TOPIC_MAP = [
            {
                "match": ['tmi', 'tranche', 'marginal', 'imposition', 'bar√®me', 'imp√¥t sur le revenu', 'ir', 'imp√¥t', 'impots', 'payer', 'quotient', 'part'],
                "enhanced": "article 197 CGI imp√¥t sur le revenu bar√®me progressif tranches marginales taux imposition",
                "keywords": ['197', 'bar√®me', 'tranche', 'taux', 'imp√¥t', 'revenu', 'quotient', 'part']
            },
            {
                "match": ['tva', 'taxe valeur ajout√©e', 'taux tva'],
                "enhanced": "article 278 279 CGI TVA taux normal r√©duit super-r√©duit taxe valeur ajout√©e",
                "keywords": ['278', '279', 'tva', 'taux', 'taxe']
            },
            {
                "match": ['r√©duction', 'cr√©dit', 'd√©duction', 'avantage fiscal', 'credit d\'imp√¥t', 'cr√©dit d\'impot'],
                "enhanced": "article 199 200 CGI r√©duction cr√©dit imp√¥t d√©duction fiscale avantage",
                "keywords": ['199', '200', 'r√©duction', 'cr√©dit', 'd√©duction']
            },
            {
                "match": ['plus-value', 'plus value', 'cession', 'vente', 'pv', 'plusvalues'],
                "enhanced": "article 150 CGI plus-value cession vente immobilier actions",
                "keywords": ['150', 'plus-value', 'cession', 'vente']
            },
            {
                "match": ['sci', 'soci√©t√© civile', 'immobilier', 'sci familiale'],
                "enhanced": "CGI soci√©t√© civile immobili√®re SCI r√©gime fiscal imposition",
                "keywords": ['sci', 'soci√©t√©', 'civile', 'immobili√®re']
            },
            {
                "match": ['is', 'imp√¥t sur les soci√©t√©s', 'impot sur les societes', 'b√©n√©fice imposable', 'resultat fiscal'],
                "enhanced": "article 209 CGI imp√¥t sur les soci√©t√©s base imposable taux",
                "keywords": ['209', 'imp√¥t', 'soci√©t√©s', 'is', 'taux']
            },
            {
                "match": ['ifi', 'fortune', 'immobili√®re', 'imp√¥t sur la fortune immobili√®re'],
                "enhanced": "article 964 CGI imp√¥t sur la fortune immobili√®re assiette exon√©rations",
                "keywords": ['964', 'ifi', 'fortune', 'immobili√®re']
            },
            {
                "match": ['cvae', 'cfe', 'cotisation fonci√®re', 'cotisation sur la valeur ajout√©e'],
                "enhanced": "article 1586 CGI cfe cvae cotisation locale valeur ajout√©e entreprises",
                "keywords": ['1586', 'cfe', 'cvae', 'cotisation']
            }
        ]

        enhanced_query = None
        keywords = []
        for topic in TOPIC_MAP:
            if any(term in query_lower for term in topic["match"]):
                enhanced_query = topic["enhanced"]
                keywords = topic["keywords"]
                break

        # Fallback g√©n√©rique
        if enhanced_query is None:
            # Utiliser directement la requ√™te de l'utilisateur (sans pr√©fixe g√©n√©rique)
            enhanced_query = query  # Pas de pr√©fixe "CGI ..." pour √©viter un bruit inutile
            keywords = [word for word in query_lower.split() if len(word) > 3]
        
        # print(f"üîç Requ√™te de recherche am√©lior√©e : {enhanced_query}") # Supprim√© car trop verbeux
        
        # Recherche avec plus de r√©sultats pour filtrage
        similar_articles_raw = search_similar_articles(enhanced_query, _embeddings_cache, top_k=max_results * 4)
        
        # G√©rer le nouveau format √©ventuel (tuples) et pr√©server la similarit√©
        similar_articles = []
        for art in similar_articles_raw:
            if isinstance(art, tuple) and len(art) >= 2:
                article_data, sim_score = art[0], art[1]
                # Conserver la similarit√© pour le scoring
                article_data['similarity'] = sim_score
                similar_articles.append(article_data)
            else:
                similar_articles.append(art)
        
        # Scoring et filtrage avanc√© des r√©sultats AVEC validation des sources
        scored_articles = []
        for article_data in similar_articles[:max_results]:
            # VALIDATION STRICTE : V√©rifier que c'est bien du CGI
            if not validate_official_source({'type': 'CGI', 'path': 'cgi_chunks'}):
                continue  # Ignorer les sources non officielles
            
            content = article_data.get('text', '').lower()
            article_num = article_data.get('article_number', '')
            
            # Score bas√© sur la pr√©sence des mots-cl√©s
            keyword_score = sum(1 for keyword in keywords if keyword in content) / max(len(keywords), 1)
            
            # Score bonus si l'article est mentionn√© directement
            article_mention_score = 1.0 if f"article {article_num}" in query_lower else 0.0
            
            # Score combin√©
            similarity = getattr(article_data, 'similarity', 0.5)  # Fallback si pas de similarit√©
            final_score = (similarity * 0.7) + (keyword_score * 0.2) + (article_mention_score * 0.1)
            
            scored_articles.append({
                **article_data,
                'final_score': final_score
            })
        
        # Trier par score final et prendre les meilleurs
        scored_articles.sort(key=lambda x: x['final_score'], reverse=True)
        
        # Formatage des r√©sultats avec plus de contexte
        results = []
        for i, article_data in enumerate(scored_articles[:max_results]):
            # Pour les 3 premiers articles, prendre TOUT le texte
            if i < 3:
                text = article_data.get('text', '')  # Texte complet sans limitation
            else:
                # Pour les articles suivants, extraire la partie pertinente
                text = article_data.get('text', '')
                if len(text) > 3000:
                    # Chercher les paragraphes contenant les mots-cl√©s
                    paragraphs = text.split('\n')
                    relevant_paragraphs = []
                    for para in paragraphs:
                        if any(keyword in para.lower() for keyword in keywords):
                            relevant_paragraphs.append(para)
                    
                    if relevant_paragraphs:
                        text = '\n'.join(relevant_paragraphs[:5])[:3000]
                    else:
                        text = text[:3000]
            
            # print(f"üìÑ Article trouv√© : {article_data.get('article_number', 'N/A')} avec score {article_data.get('final_score', 0)}") # Supprim√© car trop verbeux
            results.append({
                'content': text,
                'source': f"CGI Article {article_data.get('article_number', 'N/A')}",
                'article_id': article_data.get('article_number', 'N/A')
            })
        
        return results
    except Exception as e:
        print(f"Erreur dans search_cgi_embeddings: {e}")
        return []  # Fallback silencieux

# Fonction de compatibilit√© pour l'ancien syst√®me
def get_relevant_context(query: str) -> str:
    """R√©cup√®re le contexte pertinent UNIQUEMENT depuis les sources officielles."""
    context = ""
    
    # Recherche CGI
    cgi_articles = search_cgi_embeddings(query, max_results=3)
    if cgi_articles:
        context += "=== CODE G√âN√âRAL DES IMP√îTS ===\n"
        for article in cgi_articles:
            context += f"{article['source']}: {article['content'][:1000]}...\n\n"
    
    # Recherche BOFiP
    bofip_chunks = search_bofip_embeddings(query, max_results=2)
    if bofip_chunks:
        context += "=== BULLETIN OFFICIEL DES FINANCES PUBLIQUES ===\n"
        for chunk in bofip_chunks:
            context += f"BOFiP: {chunk.get('text', '')[:1000]}...\n\n"
    
    return context if context else "Aucune source officielle trouv√©e pour cette question."

# NOUVELLE FONCTION STREAMING
async def get_fiscal_response_stream(query: str, conversation_history: List[Dict] = None, user_profile_context: Optional[Dict[str, typing.Any]] = None, jurisdiction: Literal["FR", "AD", "CH", "LU"] = "FR") -> AsyncGenerator[str, None]:
    """G√©n√®re une r√©ponse fiscale en streaming (actuellement, une seule r√©ponse compl√®te)."""
    try:
        answer, sources, confidence = get_fiscal_response(query, conversation_history, user_profile_context, jurisdiction)
        
        response_data = {
            "type": "full_response",
            "answer": answer,
            "sources": sources,
            "confidence": confidence,
            "status": "success"
        }
        yield json.dumps(response_data) + "\n"
        
    except Exception as e:
        error_message = f"Erreur lors du traitement de la question en streaming: {str(e)}"
        print(error_message)
        error_response = {
            "type": "error",
            "message": error_message,
            "status": "error"
        }
        yield json.dumps(error_response) + "\n"

def main():
    """Test principal pour d√©veloppement local."""
    query = "Quelle est ma TMI si je gagne 50000‚Ç¨ ?"
    answer, sources, confidence = get_fiscal_response(query)
    print(f"R√©ponse: {answer}")
    print(f"Sources: {sources}")
    print(f"Confiance: {confidence}")

if __name__ == "__main__":
    main()
