"""
FRANCIS PARTICULIER IND√âPENDANT - ASSISTANT FISCAL EUROP√âEN 100% AUTONOME
=========================================================================

Assistant fiscal sp√©cialis√© pour les particuliers avec connaissance compl√®te
de la fiscalit√© europ√©enne. Syst√®me totalement ind√©pendant sans d√©pendance externe.

Fonctionnalit√©s :
- Conseil fiscal personnalis√© pour 35 pays europ√©ens
- Calculs d'imp√¥ts pr√©cis et optimisation fiscale
- Comparaisons internationales et recommandations de r√©sidence
- Support multilingue et mise √† jour automatique
- Interface conversationnelle naturelle
"""

import os
import json
import re
import requests
import time
import hashlib
from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
from datetime import datetime, timedelta
import asyncio
from functools import lru_cache
import threading
from collections import defaultdict

# Import de la base de connaissance europ√©enne
from european_tax_knowledge_base import (
    european_tax_kb, 
    get_european_tax_response,
    EuropeanTaxKnowledgeBase
)

class OllamaClient:
    """Client avanc√© pour communiquer avec Ollama en local"""
    
    def __init__(self, base_url: str = None, model: str = "mistral:7b-instruct"):
        # Utiliser la variable d'environnement ou localhost par d√©faut
        self.base_url = base_url or os.getenv("LLM_ENDPOINT", "http://localhost:11434")
        self.model = model
        self.models_cache = {}
        self.performance_stats = {
            "requests_count": 0,
            "avg_response_time": 0,
            "success_rate": 0,
            "errors": []
        }
    
    def is_available(self) -> bool:
        """V√©rifie si Ollama est disponible avec cache intelligent"""
        try:
            start_time = time.time()
            response = requests.get(f"{self.base_url}/api/tags", timeout=3)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                # Cache des mod√®les disponibles
                try:
                    self.models_cache = {m['name']: m for m in response.json().get('models', [])}
                except:
                    pass
                return True
            return False
        except Exception as e:
            self.performance_stats["errors"].append({
                "timestamp": time.time(),
                "error": str(e),
                "type": "availability_check"
            })
            return False
    
    def generate_response(self, prompt: str, system_prompt: str = "", temperature: float = 0.3) -> str:
        """G√©n√®re une r√©ponse avec Ollama avec monitoring avanc√©"""
        start_time = time.time()
        self.performance_stats["requests_count"] += 1
        
        try:
            # Optimisation du prompt pour de meilleures performances
            optimized_prompt = self._optimize_prompt(prompt)
            
            payload = {
                "model": self.model,
                "prompt": optimized_prompt,
                "system": system_prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "top_p": 0.9,
                    "num_ctx": 8192,  # Contexte √©largi
                    "num_predict": 2048,
                    "repeat_penalty": 1.1,
                    "stop": ["\n\n\n", "---", "###"]
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=45
            )
            
            response_time = time.time() - start_time
            self._update_performance_stats(response_time, True)
            
            if response.status_code == 200:
                result = response.json().get("response", "")
                return self._post_process_response(result)
            else:
                self._update_performance_stats(response_time, False)
                return ""
                
        except Exception as e:
            response_time = time.time() - start_time
            self._update_performance_stats(response_time, False)
            self.performance_stats["errors"].append({
                "timestamp": time.time(),
                "error": str(e),
                "type": "generation",
                "prompt_length": len(prompt)
            })
            print(f"Erreur Ollama: {e}")
            return ""
    
    def _optimize_prompt(self, prompt: str) -> str:
        """Optimise le prompt pour de meilleures performances"""
        # Nettoyage et optimisation du prompt
        optimized = prompt.strip()
        # Limitation de la longueur si n√©cessaire
        if len(optimized) > 4000:
            optimized = optimized[:4000] + "..."
        return optimized
    
    def _post_process_response(self, response: str) -> str:
        """Post-traitement de la r√©ponse pour am√©liorer la qualit√©"""
        # Nettoyage de la r√©ponse
        cleaned = response.strip()
        # Suppression des r√©p√©titions
        lines = cleaned.split('\n')
        unique_lines = []
        for line in lines:
            if line not in unique_lines or len(unique_lines) == 0:
                unique_lines.append(line)
        return '\n'.join(unique_lines)
    
    def _update_performance_stats(self, response_time: float, success: bool):
        """Met √† jour les statistiques de performance"""
        # Calcul de la moyenne mobile du temps de r√©ponse
        current_avg = self.performance_stats["avg_response_time"]
        count = self.performance_stats["requests_count"]
        self.performance_stats["avg_response_time"] = (
            (current_avg * (count - 1) + response_time) / count
        )
        
        # Calcul du taux de succ√®s
        if hasattr(self, '_success_count'):
            if success:
                self._success_count += 1
        else:
            self._success_count = 1 if success else 0
        
        self.performance_stats["success_rate"] = (
            self._success_count / count * 100
        )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de performance"""
        return {
            **self.performance_stats,
            "models_available": len(self.models_cache),
            "current_model": self.model,
            "recent_errors": self.performance_stats["errors"][-5:]  # 5 derni√®res erreurs
        }

class FrancisParticulierIndependent:
    """
    Francis Particulier - Assistant fiscal europ√©en 100% ind√©pendant
    Version am√©lior√©e avec cache intelligent, analytics et optimisations
    """
    
    def __init__(self):
        self.knowledge_base = european_tax_kb
        self.conversation_history = []
        self.user_profile = {}
        self.ollama_client = OllamaClient()
        
        # Cache intelligent pour les r√©ponses
        self.response_cache = {}
        self.cache_ttl = 3600  # 1 heure
        
        # Analytics et m√©triques
        self.analytics = {
            "queries_processed": 0,
            "countries_queried": defaultdict(int),
            "query_types": defaultdict(int),
            "response_times": [],
            "user_satisfaction": [],
            "cache_hits": 0,
            "cache_misses": 0
        }
        
        # Configuration avanc√©e
        self.config = {
            "enable_cache": True,
            "enable_analytics": True,
            "max_response_length": 5000,
            "enable_smart_suggestions": True,
            "enable_context_memory": True,
            "response_quality_threshold": 0.8
        }
        
        # Thread lock pour la s√©curit√©
        self._lock = threading.Lock()
        
        # Patterns de reconnaissance des questions fiscales (am√©lior√©s)
        self.tax_patterns = {
            "income_tax": [
                r"imp√¥t.*revenu", r"tmi", r"taux.*marginal", r"income.*tax",
                r"combien.*imp√¥t", r"calcul.*imp√¥t", r"je.*dois.*payer",
                r"bar√®me.*fiscal", r"tranches.*imposition", r"revenus.*imposables"
            ],
            "vat": [
                r"tva", r"taxe.*valeur.*ajout√©e", r"vat", r"value.*added.*tax",
                r"taux.*tva", r"r√©cup√©ration.*tva", r"d√©duction.*tva"
            ],
            "optimization": [
                r"optimis", r"r√©duire.*imp√¥t", r"√©conomiser", r"d√©fiscalis",
                r"conseil.*fiscal", r"strat√©gie.*fiscal", r"planification.*fiscal",
                r"niches.*fiscal", r"investissement.*d√©fiscalis", r"√©pargne.*retraite"
            ],
            "comparison": [
                r"compar", r"meilleur.*pays", r"o√π.*payer.*moins", r"diff√©rence.*pays",
                r"expatri", r"r√©sidence.*fiscal", r"d√©localisation.*fiscal",
                r"avantages.*fiscal.*pays", r"fiscalit√©.*europ√©enne"
            ],
            "social_security": [
                r"cotisation.*social", r"s√©curit√©.*social", r"social.*security",
                r"charges.*social", r"urssaf", r"csg.*crds", r"pr√©l√®vements.*sociaux"
            ],
            "wealth_tax": [
                r"imp√¥t.*fortune", r"isf", r"ifi", r"wealth.*tax", r"patrimoine",
                r"biens.*immobiliers", r"actifs.*financiers", r"d√©claration.*patrimoine"
            ],
            "capital_gains": [
                r"plus.*value", r"gain.*capital", r"capital.*gains", r"cession",
                r"vente.*actions", r"vente.*immobilier", r"abattement.*dur√©e"
            ],
            "inheritance_tax": [
                r"succession", r"h√©ritage", r"donation", r"transmission.*patrimoine",
                r"droits.*succession", r"abattement.*famille"
            ],
            "business_tax": [
                r"imp√¥t.*soci√©t√©", r"is", r"b√©n√©fices.*industriels", r"bic", r"bnc",
                r"auto.*entrepreneur", r"micro.*entreprise", r"tva.*intracommunautaire"
            ]
        }
    
    def _generate_cache_key(self, query: str, user_profile: Optional[Dict] = None) -> str:
        """G√©n√®re une cl√© de cache unique pour la requ√™te"""
        profile_str = json.dumps(user_profile or {}, sort_keys=True)
        combined = f"{query.lower().strip()}|{profile_str}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def _is_cache_valid(self, timestamp: float) -> bool:
        """V√©rifie si l'entr√©e de cache est encore valide"""
        return time.time() - timestamp < self.cache_ttl
    
    def _update_analytics(self, query: str, analysis: Dict, response_time: float):
        """Met √† jour les analytics de performance"""
        if not self.config["enable_analytics"]:
            return
            
        with self._lock:
            self.analytics["queries_processed"] += 1
            self.analytics["response_times"].append(response_time)
            
            # Garde seulement les 1000 derniers temps de r√©ponse
            if len(self.analytics["response_times"]) > 1000:
                self.analytics["response_times"] = self.analytics["response_times"][-1000:]
            
            # Statistiques par type de requ√™te
            query_type = analysis.get("query_type", "general")
            self.analytics["query_types"][query_type] += 1
            
            # Statistiques par pays
            for country in analysis.get("countries_mentioned", []):
                self.analytics["countries_queried"][country] += 1
    
    def get_analytics_summary(self) -> Dict[str, Any]:
        """Retourne un r√©sum√© des analytics"""
        with self._lock:
            response_times = self.analytics["response_times"]
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0
            
            return {
                "total_queries": self.analytics["queries_processed"],
                "avg_response_time_ms": round(avg_response_time * 1000, 2),
                "cache_hit_rate": (
                    self.analytics["cache_hits"] / 
                    (self.analytics["cache_hits"] + self.analytics["cache_misses"]) * 100
                    if (self.analytics["cache_hits"] + self.analytics["cache_misses"]) > 0 else 0
                ),
                "top_countries": dict(sorted(
                    self.analytics["countries_queried"].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )[:10]),
                "top_query_types": dict(sorted(
                    self.analytics["query_types"].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )),
                "ollama_stats": self.ollama_client.get_performance_stats()
            }
    
    @lru_cache(maxsize=128)
    def _get_smart_suggestions(self, query_type: str, countries: tuple) -> List[str]:
        """G√©n√®re des suggestions intelligentes bas√©es sur le contexte"""
        suggestions = []
        
        if query_type == "income_tax":
            suggestions.extend([
                "Voulez-vous comparer avec d'autres pays europ√©ens ?",
                "Souhaitez-vous des conseils d'optimisation fiscale ?",
                "Avez-vous des revenus de source √©trang√®re ?"
            ])
        elif query_type == "optimization":
            suggestions.extend([
                "Consid√©rez-vous un changement de r√©sidence fiscale ?",
                "Avez-vous explor√© les dispositifs d'√©pargne retraite ?",
                "Souhaitez-vous optimiser votre patrimoine immobilier ?"
            ])
        elif query_type == "comparison":
            suggestions.extend([
                "Voulez-vous une analyse d√©taill√©e des co√ªts de relocalisation ?",
                "Souhaitez-vous conna√Ætre les obligations d√©claratives ?",
                "Avez-vous besoin d'informations sur les conventions fiscales ?"
            ])
        
        return suggestions[:3]  # Limite √† 3 suggestions
    
    def analyze_query(self, query: str) -> Dict[str, Any]:
        """Analyse la requ√™te utilisateur pour d√©terminer le type de question fiscale"""
        
        # Analyse basique avec patterns (fallback)
        basic_analysis = self._basic_pattern_analysis(query)
        
        # Analyse intelligente avec LLM local si disponible
        if self.ollama_client.is_available():
            llm_analysis = self._llm_query_analysis(query)
            # Fusion des analyses
            return self._merge_analyses(basic_analysis, llm_analysis)
        else:
            print("‚ö†Ô∏è Ollama non disponible, utilisation de l'analyse basique")
            return basic_analysis
    
    def _basic_pattern_analysis(self, query: str) -> Dict[str, Any]:
        """Analyse basique avec patterns regex (m√©thode de fallback)"""
        query_lower = query.lower()
        
        analysis = {
            "query_type": "general",
            "tax_topics": [],
            "countries_mentioned": [],
            "amounts_mentioned": [],
            "confidence": 0.0
        }
        
        # D√©tection des sujets fiscaux
        for topic, patterns in self.tax_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    analysis["tax_topics"].append(topic)
                    analysis["confidence"] += 0.2
        
        # D√©tection des pays mentionn√©s
        country_patterns = {
            "france": "FR", "allemagne": "DE", "germany": "DE", "suisse": "CH", 
            "switzerland": "CH", "andorre": "AD", "andorra": "AD", 
            "luxembourg": "LU", "danemark": "DK", "denmark": "DK",
            "hongrie": "HU", "hungary": "HU", "estonie": "EE", "estonia": "EE",
            "italie": "IT", "italy": "IT", "espagne": "ES", "spain": "ES",
            "portugal": "PT", "belgique": "BE", "belgium": "BE",
            "pays-bas": "NL", "netherlands": "NL", "autriche": "AT", "austria": "AT"
        }
        
        for country_name, country_code in country_patterns.items():
            if country_name in query_lower:
                analysis["countries_mentioned"].append(country_code)
                analysis["confidence"] += 0.1
        
        # D√©tection des montants
        amount_patterns = [
            r'(\d+(?:\s*\d+)*)\s*(?:‚Ç¨|euros?)',
            r'(\d+(?:\s*\d+)*)\s*k‚Ç¨',
            r'(\d+(?:\s*\d+)*)\s*(?:dollars?|\$)',
            r'(\d+(?:\s*\d+)*)\s*(?:chf|francs?)'
        ]
        
        for pattern in amount_patterns:
            matches = re.findall(pattern, query_lower)
            for match in matches:
                amount_str = match.replace(' ', '')
                if 'k‚Ç¨' in query_lower:
                    amount = float(amount_str) * 1000
                else:
                    amount = float(amount_str)
                analysis["amounts_mentioned"].append(amount)
                analysis["confidence"] += 0.1
        
        # D√©termination du type de requ√™te principal
        if analysis["tax_topics"]:
            analysis["query_type"] = analysis["tax_topics"][0]
        
        return analysis
    
    def _llm_query_analysis(self, query: str) -> Dict[str, Any]:
        """Analyse intelligente de la requ√™te avec LLM local"""
        
        system_prompt = """Tu es Francis, un expert fiscal europ√©en. Analyse cette question fiscale et extrait les informations cl√©s.

R√©ponds UNIQUEMENT en JSON avec cette structure exacte :
{
    "query_type": "income_tax|vat|optimization|comparison|social_security|wealth_tax|capital_gains|general",
    "tax_topics": ["liste des sujets fiscaux identifi√©s"],
    "countries_mentioned": ["codes pays ISO (FR, DE, CH, etc.)"],
    "amounts_mentioned": [montants num√©riques extraits],
    "confidence": 0.95,
    "intent": "description courte de l'intention"
}

Pays support√©s et leurs codes :
- France: FR, Allemagne: DE, Suisse: CH, Andorre: AD, Luxembourg: LU
- Danemark: DK, Hongrie: HU, Estonie: EE, Italie: IT, Espagne: ES
- Portugal: PT, Belgique: BE, Pays-Bas: NL, Autriche: AT

Sois pr√©cis dans l'extraction des montants et des pays."""

        prompt = f"Question fiscale √† analyser : '{query}'"
        
        llm_response = self.ollama_client.generate_response(prompt, system_prompt)
        
        try:
            # Extraction du JSON de la r√©ponse
            json_start = llm_response.find('{')
            json_end = llm_response.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                json_str = llm_response[json_start:json_end]
                analysis = json.loads(json_str)
                analysis["llm_used"] = True
                return analysis
        except:
            pass
        
        # Fallback si l'analyse LLM √©choue
        return {
            "query_type": "general",
            "tax_topics": [],
            "countries_mentioned": [],
            "amounts_mentioned": [],
            "confidence": 0.3,
            "llm_used": False
        }
    
    def _merge_analyses(self, basic: Dict, llm: Dict) -> Dict[str, Any]:
        """Fusionne les analyses basique et LLM pour plus de pr√©cision"""
        
        # Priorit√© √† l'analyse LLM si elle est plus confiante
        if llm.get("confidence", 0) > basic.get("confidence", 0):
            merged = llm.copy()
            # Ajout des √©l√©ments manqu√©s par le LLM mais d√©tect√©s par les patterns
            merged["countries_mentioned"] = list(set(
                merged.get("countries_mentioned", []) + 
                basic.get("countries_mentioned", [])
            ))
            merged["amounts_mentioned"] = list(set(
                merged.get("amounts_mentioned", []) + 
                basic.get("amounts_mentioned", [])
            ))
        else:
            merged = basic.copy()
            # Enrichissement avec les insights du LLM
            if "intent" in llm:
                merged["intent"] = llm["intent"]
        
        merged["analysis_method"] = "hybrid" if llm.get("llm_used") else "basic"
        
        # Ajout de suggestions intelligentes
        if self.config["enable_smart_suggestions"]:
            countries_tuple = tuple(merged.get("countries_mentioned", []))
            merged["smart_suggestions"] = self._get_smart_suggestions(
                merged["query_type"], countries_tuple
            )
        
        return merged
    
    def generate_response(self, query: str, user_profile: Optional[Dict] = None) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse fiscale compl√®te et personnalis√©e avec cache intelligent
        
        Args:
            query: Question de l'utilisateur
            user_profile: Profil utilisateur optionnel
        
        Returns:
            R√©ponse structur√©e avec conseils fiscaux
        """
        start_time = time.time()
        
        # V√©rification du cache
        cache_key = self._generate_cache_key(query, user_profile)
        if self.config["enable_cache"] and cache_key in self.response_cache:
            cached_entry = self.response_cache[cache_key]
            if self._is_cache_valid(cached_entry["timestamp"]):
                self.analytics["cache_hits"] += 1
                cached_response = cached_entry["response"].copy()
                cached_response["from_cache"] = True
                cached_response["cache_age_seconds"] = int(time.time() - cached_entry["timestamp"])
                return cached_response
            else:
                # Cache expir√©, suppression
                del self.response_cache[cache_key]
        
        self.analytics["cache_misses"] += 1
        
        # Analyse de la requ√™te
        analysis = self.analyze_query(query)
        
        # Mise √† jour du profil utilisateur avec m√©moire contextuelle
        if user_profile:
            self.user_profile.update(user_profile)
        
        # Ajout du contexte de conversation si activ√©
        if self.config["enable_context_memory"] and self.conversation_history:
            analysis["conversation_context"] = self.conversation_history[-3:]  # 3 derniers √©changes
        
        # G√©n√©ration de la r√©ponse selon le type de requ√™te
        if analysis["query_type"] == "income_tax":
            base_response = self._handle_income_tax_query(query, analysis)
        elif analysis["query_type"] == "comparison":
            base_response = self._handle_comparison_query(query, analysis)
        elif analysis["query_type"] == "optimization":
            base_response = self._handle_optimization_query(query, analysis)
        elif analysis["query_type"] == "vat":
            base_response = self._handle_vat_query(query, analysis)
        elif analysis["query_type"] == "inheritance_tax":
            base_response = self._handle_inheritance_tax_query(query, analysis)
        elif analysis["query_type"] == "business_tax":
            base_response = self._handle_business_tax_query(query, analysis)
        else:
            base_response = self._handle_general_query(query, analysis)
        
        # Enrichissement avec LLM local si disponible
        if self.ollama_client.is_available() and analysis.get("analysis_method") == "hybrid":
            base_response = self._enrich_response_with_llm(query, base_response, analysis)
        
        # Ajout des suggestions intelligentes
        if "smart_suggestions" in analysis:
            base_response["smart_suggestions"] = analysis["smart_suggestions"]
        
        # Limitation de la longueur de r√©ponse
        if len(base_response.get("response", "")) > self.config["max_response_length"]:
            base_response["response"] = base_response["response"][:self.config["max_response_length"]] + "\n\n*[R√©ponse tronqu√©e pour optimiser la performance]*"
            base_response["truncated"] = True
        
        # Mise en cache de la r√©ponse
        if self.config["enable_cache"]:
            self.response_cache[cache_key] = {
                "response": base_response.copy(),
                "timestamp": time.time()
            }
            
            # Nettoyage du cache si trop volumineux
            if len(self.response_cache) > 500:
                oldest_keys = sorted(
                    self.response_cache.keys(),
                    key=lambda k: self.response_cache[k]["timestamp"]
                )[:100]
                for key in oldest_keys:
                    del self.response_cache[key]
        
        # Mise √† jour des analytics
        response_time = time.time() - start_time
        self._update_analytics(query, analysis, response_time)
        
        # Ajout √† l'historique de conversation
        if self.config["enable_context_memory"]:
            self.conversation_history.append({
                "query": query,
                "response_type": base_response.get("type", "unknown"),
                "timestamp": time.time(),
                "analysis": analysis
            })
            
            # Limitation de l'historique
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
        
        # M√©tadonn√©es de performance
        base_response["performance"] = {
            "response_time_ms": round(response_time * 1000, 2),
            "from_cache": False,
            "analysis_method": analysis.get("analysis_method", "basic"),
            "llm_enriched": base_response.get("enriched_by_llm", False)
        }
        
        return base_response
    
    def _enrich_response_with_llm(self, query: str, base_response: Dict, analysis: Dict) -> Dict[str, Any]:
        """Enrichit la r√©ponse avec des explications personnalis√©es du LLM local"""
        
        system_prompt = """Tu es Francis, expert fiscal europ√©en. Tu dois enrichir une r√©ponse fiscale technique avec des explications claires et personnalis√©es.

R√àGLES IMPORTANTES :
- Garde TOUJOURS les calculs et donn√©es factuelles existants
- Ajoute des explications p√©dagogiques et du contexte
- Personnalise selon la situation de l'utilisateur
- Utilise un ton professionnel mais accessible
- Ajoute des conseils pratiques pertinents
- Reste factuel et pr√©cis

R√©ponds en markdown avec la structure existante enrichie."""

        prompt = f"""
Question originale : "{query}"
Type de requ√™te : {analysis.get('query_type', 'general')}
Intention : {analysis.get('intent', 'Non d√©finie')}

R√©ponse technique actuelle :
{base_response.get('response', '')}

Enrichis cette r√©ponse avec :
1. Une introduction personnalis√©e
2. Des explications claires des concepts fiscaux
3. Des conseils pratiques adapt√©s
4. Une conclusion avec prochaines √©tapes recommand√©es

Garde TOUS les calculs, tableaux et donn√©es existants.
"""
        
        enriched_text = self.ollama_client.generate_response(prompt, system_prompt)
        
        if enriched_text and len(enriched_text) > 100:
            base_response["response"] = enriched_text
            base_response["enriched_by_llm"] = True
        else:
            base_response["enriched_by_llm"] = False
        
        return base_response
    
    def _handle_income_tax_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions sur l'imp√¥t sur le revenu"""
        
        # Extraction des param√®tres
        income = analysis["amounts_mentioned"][0] if analysis["amounts_mentioned"] else 50000
        country = analysis["countries_mentioned"][0] if analysis["countries_mentioned"] else "FR"
        
        # Calcul de l'imp√¥t
        tax_calculation = self.knowledge_base.calculate_income_tax(country, income)
        
        # G√©n√©ration de la r√©ponse
        response = f"""
## üí∞ Calcul de l'imp√¥t sur le revenu - {tax_calculation['country']}

**Revenus analys√©s :** {income:,.0f} {tax_calculation['currency']}

### üìä R√©sultat du calcul :
- **Imp√¥t sur le revenu :** {tax_calculation['income_tax']:,.0f} {tax_calculation['currency']}
- **Cotisations sociales :** {tax_calculation['social_security']:,.0f} {tax_calculation['currency']}
- **Total des pr√©l√®vements :** {tax_calculation['total_tax']:,.0f} {tax_calculation['currency']}
- **Revenu net :** {tax_calculation['net_income']:,.0f} {tax_calculation['currency']}

### üìà Taux d'imposition :
- **Taux effectif :** {tax_calculation['effective_rate']}%
- **Taux marginal :** {tax_calculation['marginal_rate']}%

### üîç D√©tail par tranches :
"""
        
        for bracket in tax_calculation['tax_breakdown']:
            response += f"- **{bracket['bracket']} {tax_calculation['currency']}** √† {bracket['rate']} : {bracket['tax_amount']:,.0f} {tax_calculation['currency']}\n"
        
        # Conseils personnalis√©s
        if tax_calculation['effective_rate'] > 30:
            response += f"""
### üí° Conseils d'optimisation :
- Votre taux effectif de {tax_calculation['effective_rate']}% est √©lev√©
- Consid√©rez les dispositifs de d√©fiscalisation disponibles
- Une optimisation internationale pourrait √™tre b√©n√©fique
"""
        
        return {
            "response": response,
            "calculation": tax_calculation,
            "type": "income_tax_calculation",
            "confidence": 0.95
        }
    
    def _handle_comparison_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions de comparaison entre pays"""
        
        income = analysis["amounts_mentioned"][0] if analysis["amounts_mentioned"] else 75000
        countries = analysis["countries_mentioned"] if analysis["countries_mentioned"] else ["FR", "DE", "CH", "AD", "LU"]
        
        # Comparaison entre pays
        comparison = self.knowledge_base.compare_countries(income, countries)
        
        response = f"""
## üåç Comparaison fiscale europ√©enne

**Revenus compar√©s :** {income:,.0f} ‚Ç¨

### üèÜ Classement par charge fiscale totale :
"""
        
        rank = 1
        for country_code, data in comparison["countries_comparison"].items():
            flag = self._get_country_flag(country_code)
            response += f"{rank}. {flag} **{data['country']}** : {data['total_tax']:,.0f} {data['currency']} ({data['effective_rate']}%)\n"
            rank += 1
        
        if comparison["tax_savings"] > 0:
            response += f"""
### üí∞ √âconomie potentielle :
En d√©m√©nageant de {comparison["countries_comparison"][comparison["worst_country"]]["country"]} vers {comparison["countries_comparison"][comparison["best_country"]]["country"]}, vous pourriez √©conomiser **{comparison["tax_savings"]:,.0f} ‚Ç¨** par an !

### üéØ Pays recommand√© : {comparison["countries_comparison"][comparison["best_country"]]["country"]}
- Charge fiscale totale : {comparison["countries_comparison"][comparison["best_country"]]["total_tax"]:,.0f} ‚Ç¨
- Taux effectif : {comparison["countries_comparison"][comparison["best_country"]]["effective_rate"]}%
"""
        
        return {
            "response": response,
            "comparison": comparison,
            "type": "country_comparison",
            "confidence": 0.9
        }
    
    def _handle_optimization_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions d'optimisation fiscale"""
        
        # Profil par d√©faut ou utilisateur
        profile = self.user_profile or {
            "annual_income": analysis["amounts_mentioned"][0] if analysis["amounts_mentioned"] else 80000,
            "country": analysis["countries_mentioned"][0] if analysis["countries_mentioned"] else "FR",
            "objectives": ["reduce_tax", "optimize_wealth"]
        }
        
        advice = self.knowledge_base.get_tax_optimization_advice(profile)
        
        response = f"""
## üéØ Conseils d'optimisation fiscale personnalis√©s

### üìä Votre situation actuelle :
- **Pays :** {advice['current_situation']['country']}
- **Revenus :** {profile['annual_income']:,.0f} ‚Ç¨
- **Charge fiscale :** {advice['current_situation']['total_tax']:,.0f} ‚Ç¨ ({advice['current_situation']['effective_rate']}%)

### üí° Strat√©gies recommand√©es :
"""
        
        for i, strategy in enumerate(advice['tax_strategies'], 1):
            response += f"{i}. {strategy}\n"
        
        if advice['recommended_countries']:
            response += f"""
### üåç Pays avantageux pour votre profil :
"""
            for country in advice['recommended_countries']:
                flag = self._get_country_flag(country['country'])
                response += f"""
**{flag} {self.knowledge_base.countries_data[country['country']].country_name}**
- √âconomie annuelle : {country['tax_savings']:,.0f} ‚Ç¨
- Taux effectif : {country['effective_rate']}%
- Avantages : {', '.join(country['advantages'][:2])}
"""
        
        return {
            "response": response,
            "advice": advice,
            "type": "tax_optimization",
            "confidence": 0.85
        }
    
    def _handle_vat_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions sur la TVA"""
        
        countries = analysis["countries_mentioned"] if analysis["countries_mentioned"] else ["FR", "DE", "CH", "AD", "LU"]
        
        response = """
## üßæ Taux de TVA en Europe

### üìä Comparaison des taux standard :
"""
        
        vat_data = []
        for country_code in countries:
            if country_code in self.knowledge_base.countries_data:
                country_data = self.knowledge_base.countries_data[country_code]
                flag = self._get_country_flag(country_code)
                response += f"- {flag} **{country_data.country_name}** : {country_data.vat_standard_rate}%"
                if country_data.vat_reduced_rates:
                    response += f" (taux r√©duits : {', '.join(map(str, country_data.vat_reduced_rates))}%)"
                response += "\n"
                
                vat_data.append({
                    "country": country_data.country_name,
                    "standard_rate": country_data.vat_standard_rate,
                    "reduced_rates": country_data.vat_reduced_rates
                })
        
        # Tri par taux croissant
        vat_data.sort(key=lambda x: x["standard_rate"])
        
        if vat_data:
            response += f"""
### üèÜ Pays avec la TVA la plus avantageuse :
**{vat_data[0]['country']}** avec {vat_data[0]['standard_rate']}%

### ‚ö†Ô∏è Pays avec la TVA la plus √©lev√©e :
**{vat_data[-1]['country']}** avec {vat_data[-1]['standard_rate']}%
"""
        
        return {
            "response": response,
            "vat_data": vat_data,
            "type": "vat_information",
            "confidence": 0.8
        }
    
    def _handle_general_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions g√©n√©rales"""
        
        # Recherche dans la base de connaissance
        search_results = self.knowledge_base.search_tax_knowledge(query)
        
        response = f"""
## üîç Recherche fiscale europ√©enne

**Votre question :** {query}

### üìö Informations trouv√©es :
"""
        
        for i, result in enumerate(search_results[:5], 1):
            flag = self._get_country_flag(result.get("country_code", ""))
            response += f"{i}. {flag} **{result['country']}** : {result['content']}\n"
        
        if not search_results:
            response += """
Aucun r√©sultat sp√©cifique trouv√©. Voici quelques suggestions :
- Pr√©cisez votre situation (revenus, pays de r√©sidence)
- Mentionnez le type d'imp√¥t qui vous int√©resse
- Indiquez vos objectifs d'optimisation fiscale
"""
        
        return {
            "response": response,
            "search_results": search_results,
            "type": "general_search",
            "confidence": 0.6
        }
    
    def _handle_inheritance_tax_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions sur les droits de succession et donations"""
        
        countries = analysis["countries_mentioned"] if analysis["countries_mentioned"] else ["FR", "DE", "CH", "AD", "LU"]
        amounts = analysis["amounts_mentioned"]
        inheritance_amount = amounts[0] if amounts else 500000
        
        response = f"""
## üèõÔ∏è Droits de succession et donations en Europe

**Patrimoine analys√© :** {inheritance_amount:,.0f} ‚Ç¨

### üìä Comparaison europ√©enne des droits de succession :
"""
        
        inheritance_data = []
        for country_code in countries:
            if country_code in self.knowledge_base.countries_data:
                country_data = self.knowledge_base.countries_data[country_code]
                flag = self._get_country_flag(country_code)
                
                # Calcul simplifi√© des droits de succession (√† am√©liorer avec donn√©es r√©elles)
                if country_code == "FR":
                    tax_rate = 20 if inheritance_amount < 100000 else 40
                elif country_code == "DE":
                    tax_rate = 15 if inheritance_amount < 200000 else 30
                elif country_code == "CH":
                    tax_rate = 5  # Tr√®s avantageux
                elif country_code == "AD":
                    tax_rate = 0  # Pas de droits de succession
                else:
                    tax_rate = 25  # Moyenne europ√©enne
                
                tax_amount = inheritance_amount * (tax_rate / 100)
                
                response += f"- {flag} **{country_data.country_name}** : {tax_rate}% = {tax_amount:,.0f} ‚Ç¨\n"
                
                inheritance_data.append({
                    "country": country_data.country_name,
                    "country_code": country_code,
                    "tax_rate": tax_rate,
                    "tax_amount": tax_amount
                })
        
        # Tri par montant croissant
        inheritance_data.sort(key=lambda x: x["tax_amount"])
        
        if inheritance_data:
            best_country = inheritance_data[0]
            worst_country = inheritance_data[-1]
            
            response += f"""

### üèÜ Pays le plus avantageux :
**{best_country['country']}** avec {best_country['tax_rate']}% ({best_country['tax_amount']:,.0f} ‚Ç¨)

### ‚ö†Ô∏è Pays le moins avantageux :
**{worst_country['country']}** avec {worst_country['tax_rate']}% ({worst_country['tax_amount']:,.0f} ‚Ç¨)

### üí∞ √âconomie potentielle :
**{worst_country['tax_amount'] - best_country['tax_amount']:,.0f} ‚Ç¨** en choisissant {best_country['country']}

### üí° Conseils strat√©giques :
- Consid√©rez la r√©sidence fiscale du d√©funt
- Explorez les conventions fiscales bilat√©rales
- Anticipez avec des donations du vivant
- Consultez les abattements familiaux disponibles
"""
        
        return {
            "response": response,
            "inheritance_data": inheritance_data,
            "type": "inheritance_tax_analysis",
            "confidence": 0.8
        }
    
    def _handle_business_tax_query(self, query: str, analysis: Dict) -> Dict[str, Any]:
        """Traite les questions sur la fiscalit√© des entreprises"""
        
        countries = analysis["countries_mentioned"] if analysis["countries_mentioned"] else ["FR", "DE", "CH", "AD", "LU"]
        amounts = analysis["amounts_mentioned"]
        business_income = amounts[0] if amounts else 100000
        
        response = f"""
## üè¢ Fiscalit√© des entreprises en Europe

**B√©n√©fices analys√©s :** {business_income:,.0f} ‚Ç¨

### üìä Taux d'imp√¥t sur les soci√©t√©s :
"""
        
        business_data = []
        for country_code in countries:
            if country_code in self.knowledge_base.countries_data:
                country_data = self.knowledge_base.countries_data[country_code]
                flag = self._get_country_flag(country_code)
                
                # Taux d'IS r√©els 2024
                corporate_rates = {
                    "FR": 25, "DE": 30, "CH": 14.9, "AD": 10, "LU": 24.94,
                    "DK": 22, "HU": 9, "EE": 20, "IT": 24, "ES": 25,
                    "PT": 21, "BE": 25, "NL": 25.8, "AT": 23
                }
                
                corporate_tax_rate = corporate_rates.get(country_code, 25)
                corporate_tax = business_income * (corporate_tax_rate / 100)
                net_income = business_income - corporate_tax
                
                response += f"- {flag} **{country_data.country_name}** : {corporate_tax_rate}% = {corporate_tax:,.0f} ‚Ç¨ (net: {net_income:,.0f} ‚Ç¨)\n"
                
                business_data.append({
                    "country": country_data.country_name,
                    "country_code": country_code,
                    "corporate_tax_rate": corporate_tax_rate,
                    "corporate_tax": corporate_tax,
                    "net_income": net_income
                })
        
        # Tri par taux croissant
        business_data.sort(key=lambda x: x["corporate_tax_rate"])
        
        if business_data:
            best_country = business_data[0]
            worst_country = business_data[-1]
            
            response += f"""

### üèÜ Pays le plus comp√©titif :
**{best_country['country']}** avec {best_country['corporate_tax_rate']}%

### üìà √âconomie d'imp√¥t potentielle :
**{worst_country['corporate_tax'] - best_country['corporate_tax']:,.0f} ‚Ç¨** par an

### üéØ Avantages fiscaux sp√©cifiques :
"""
            
            # Avantages sp√©cifiques par pays
            advantages = {
                "HU": "Taux le plus bas d'Europe (9%)",
                "AD": "R√©gime fiscal tr√®s avantageux, pas de TVA",
                "CH": "Stabilit√© fiscale, cantons comp√©titifs",
                "LU": "Holding luxembourgeoise, IP Box",
                "EE": "Pas d'imp√¥t sur b√©n√©fices non distribu√©s"
            }
            
            for country_data in business_data[:3]:
                country_code = country_data["country_code"]
                if country_code in advantages:
                    response += f"- **{country_data['country']}** : {advantages[country_code]}\n"
        
        return {
            "response": response,
            "business_data": business_data,
            "type": "business_tax_analysis",
            "confidence": 0.85
        }
    
    def _get_country_flag(self, country_code: str) -> str:
        """Retourne le drapeau emoji du pays"""
        flags = {
            "FR": "üá´üá∑", "DE": "üá©üá™", "CH": "üá®üá≠", "AD": "üá¶üá©", "LU": "üá±üá∫",
            "DK": "üá©üá∞", "HU": "üá≠üá∫", "EE": "üá™üá™", "IT": "üáÆüáπ", "ES": "üá™üá∏",
            "PT": "üáµüáπ", "BE": "üáßüá™", "NL": "üá≥üá±", "AT": "üá¶üáπ", "SE": "üá∏üá™",
            "FI": "üá´üáÆ", "NO": "üá≥üá¥", "IE": "üáÆüá™", "PL": "üáµüá±", "CZ": "üá®üáø"
        }
        return flags.get(country_code, "üè≥Ô∏è")
    
    async def generate_response_stream(self, query: str, user_profile: Optional[Dict] = None) -> AsyncGenerator[str, None]:
        """G√©n√®re une r√©ponse en streaming pour l'interface utilisateur"""
        
        # Analyse initiale
        yield json.dumps({"type": "analysis", "status": "Analyse de votre question..."}) + "\n"
        await asyncio.sleep(0.1)
        
        analysis = self.analyze_query(query)
        
        yield json.dumps({"type": "analysis", "status": f"Question identifi√©e : {analysis['query_type']}"}) + "\n"
        await asyncio.sleep(0.1)
        
        # G√©n√©ration de la r√©ponse
        yield json.dumps({"type": "processing", "status": "Calcul des donn√©es fiscales..."}) + "\n"
        await asyncio.sleep(0.2)
        
        response_data = self.generate_response(query, user_profile)
        
        yield json.dumps({"type": "response", "data": response_data}) + "\n"
    
    def clear_cache(self):
        """Vide le cache de r√©ponses"""
        with self._lock:
            self.response_cache.clear()
            print("Cache vid√© avec succ√®s")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache"""
        with self._lock:
            return {
                "cache_size": len(self.response_cache),
                "cache_hit_rate": (
                    self.analytics["cache_hits"] / 
                    (self.analytics["cache_hits"] + self.analytics["cache_misses"]) * 100
                    if (self.analytics["cache_hits"] + self.analytics["cache_misses"]) > 0 else 0
                ),
                "oldest_entry_age": (
                    time.time() - min([entry["timestamp"] for entry in self.response_cache.values()])
                    if self.response_cache else 0
                )
            }
    
    def update_config(self, new_config: Dict[str, Any]):
        """Met √† jour la configuration de Francis"""
        with self._lock:
            self.config.update(new_config)
            print(f"Configuration mise √† jour : {new_config}")
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """Retourne un r√©sum√© de la conversation actuelle"""
        if not self.conversation_history:
            return {"status": "no_conversation"}
        
        query_types = defaultdict(int)
        countries_discussed = defaultdict(int)
        
        for entry in self.conversation_history:
            analysis = entry.get("analysis", {})
            query_types[analysis.get("query_type", "unknown")] += 1
            for country in analysis.get("countries_mentioned", []):
                countries_discussed[country] += 1
        
        return {
            "total_exchanges": len(self.conversation_history),
            "duration_minutes": (
                (self.conversation_history[-1]["timestamp"] - self.conversation_history[0]["timestamp"]) / 60
                if len(self.conversation_history) > 1 else 0
            ),
            "main_topics": dict(sorted(query_types.items(), key=lambda x: x[1], reverse=True)),
            "countries_discussed": dict(sorted(countries_discussed.items(), key=lambda x: x[1], reverse=True)),
            "last_query_time": datetime.fromtimestamp(self.conversation_history[-1]["timestamp"]).isoformat()
        }
    
    def export_conversation(self) -> str:
        """Exporte la conversation au format JSON"""
        export_data = {
            "export_timestamp": datetime.now().isoformat(),
            "conversation_summary": self.get_conversation_summary(),
            "analytics_summary": self.get_analytics_summary(),
            "conversation_history": self.conversation_history,
            "user_profile": self.user_profile,
            "config": self.config
        }
        return json.dumps(export_data, indent=2, ensure_ascii=False)
    
    def get_supported_countries(self) -> List[Dict[str, str]]:
        """Retourne la liste des pays support√©s"""
        countries = []
        for code, data in self.knowledge_base.countries_data.items():
            countries.append({
                "code": code,
                "name": data.country_name,
                "flag": self._get_country_flag(code),
                "currency": data.currency,
                "eu_member": data.eu_member
            })
        return sorted(countries, key=lambda x: x["name"])
    
    def get_health_status(self) -> Dict[str, Any]:
        """Retourne l'√©tat de sant√© complet du syst√®me"""
        ollama_available = self.ollama_client.is_available()
        
        return {
            "status": "healthy" if ollama_available else "degraded",
            "timestamp": datetime.now().isoformat(),
            "components": {
                "knowledge_base": {
                    "status": "operational",
                    "countries_supported": len(self.knowledge_base.countries_data),
                    "last_updated": "2024-01-01"  # √Ä mettre √† jour dynamiquement
                },
                "ollama_llm": {
                    "status": "available" if ollama_available else "unavailable",
                    "performance": self.ollama_client.get_performance_stats()
                },
                "cache_system": {
                    "status": "operational",
                    "stats": self.get_cache_stats()
                },
                "analytics": {
                    "status": "operational",
                    "summary": self.get_analytics_summary()
                }
            },
            "capabilities": {
                "tax_calculation": True,
                "country_comparison": True,
                "optimization_advice": True,
                "inheritance_planning": True,
                "business_taxation": True,
                "intelligent_analysis": ollama_available,
                "response_enrichment": ollama_available,
                "conversation_memory": self.config["enable_context_memory"],
                "smart_caching": self.config["enable_cache"]
            }
        }

# Instance globale de Francis Particulier Ind√©pendant AM√âLIOR√â
francis_particulier = FrancisParticulierIndependent()

# Configuration par d√©faut optimis√©e
francis_particulier.update_config({
    "enable_cache": True,
    "enable_analytics": True,
    "enable_smart_suggestions": True,
    "enable_context_memory": True,
    "max_response_length": 4000,
    "response_quality_threshold": 0.85
})

def get_francis_particulier_response(query: str, user_profile: Optional[Dict] = None) -> str:
    """
    Point d'entr√©e principal pour Francis Particulier
    
    Args:
        query: Question de l'utilisateur
        user_profile: Profil utilisateur optionnel
    
    Returns:
        R√©ponse fiscale format√©e en markdown
    """
    try:
        response_data = francis_particulier.generate_response(query, user_profile)
        return response_data["response"]
    except Exception as e:
        return f"""
## ‚ùå Erreur dans le traitement de votre question

Une erreur s'est produite : {str(e)}

### üí° Suggestions :
- Reformulez votre question
- Pr√©cisez votre situation fiscale
- Mentionnez le pays qui vous int√©resse

**Francis Particulier reste √† votre disposition pour toute question fiscale europ√©enne !**
"""

# Fonction utilitaire pour les tests de performance
def run_performance_test(francis_instance, num_queries: int = 10):
    """Ex√©cute un test de performance avec plusieurs requ√™tes"""
    test_queries = [
        "Combien d'imp√¥t avec 50000‚Ç¨ en France ?",
        "Meilleur pays pour 100000‚Ç¨ ?",
        "Comment optimiser mes imp√¥ts ?",
        "Taux de TVA en Europe ?",
        "Droits de succession en Suisse ?",
        "Imp√¥t soci√©t√© en Andorre ?",
        "Comparaison fiscale France Allemagne ?",
        "Optimisation patrimoine 500000‚Ç¨ ?",
        "R√©sidence fiscale avantageuse ?",
        "Calcul charges sociales ind√©pendant ?"
    ]
    
    print(f"\nüöÄ Test de performance avec {num_queries} requ√™tes...")
    start_time = time.time()
    
    for i in range(num_queries):
        query = test_queries[i % len(test_queries)]
        response = francis_instance.generate_response(query)
        print(f"  {i+1}/{num_queries} - {response.get('performance', {}).get('response_time_ms', 0)}ms")
    
    total_time = time.time() - start_time
    analytics = francis_instance.get_analytics_summary()
    
    print(f"\nüìä R√©sultats du test de performance:")
    print(f"  Temps total: {total_time:.2f}s")
    print(f"  Temps moyen par requ√™te: {analytics['avg_response_time_ms']}ms")
    print(f"  Taux de cache hit: {analytics['cache_hit_rate']:.1f}%")
    print(f"  Requ√™tes trait√©es: {analytics['total_queries']}")

if __name__ == "__main__":
    # Tests de Francis Particulier Ind√©pendant AM√âLIOR√â
    print("=== FRANCIS PARTICULIER IND√âPENDANT AM√âLIOR√â - TESTS ===")
    
    # Test 1: Calcul d'imp√¥t
    print("\n1. Test calcul d'imp√¥t:")
    response1 = get_francis_particulier_response("Combien d'imp√¥t je paie avec 85000‚Ç¨ en France ?")
    print(response1[:200] + "...")
    
    # Test 2: Comparaison
    print("\n2. Test comparaison:")
    response2 = get_francis_particulier_response("Quel est le meilleur pays pour 100000‚Ç¨ de revenus ?")
    print(response2[:200] + "...")
    
    # Test 3: Optimisation
    print("\n3. Test optimisation:")
    profile = {"annual_income": 120000, "country": "FR"}
    response3 = get_francis_particulier_response("Comment optimiser mes imp√¥ts ?", profile)
    print(response3[:200] + "...")
    
    # Test 4: TVA
    print("\n4. Test TVA:")
    response4 = get_francis_particulier_response("Quels sont les taux de TVA en Europe ?")
    print(response4[:200] + "...")
    
    # Test de performance
    run_performance_test(francis_particulier, 5)
    
    print("\n‚úÖ Francis Particulier Ind√©pendant AM√âLIOR√â op√©rationnel !")
    print(f"üìä Pays support√©s : {len(francis_particulier.get_supported_countries())}")
    
    # Test 5: Analytics et monitoring
    print("\n5. Test analytics:")
    analytics = francis_particulier.get_analytics_summary()
    print(f"Requ√™tes trait√©es: {analytics['total_queries']}")
    print(f"Temps de r√©ponse moyen: {analytics['avg_response_time_ms']}ms")
    
    # Test 6: Health check
    print("\n6. Test health check:")
    health = francis_particulier.get_health_status()
    print(f"Statut: {health['status']}")
    print(f"Ollama disponible: {health['components']['ollama_llm']['status']}")
    
    print("\nüöÄ Francis Particulier Ind√©pendant AM√âLIOR√â op√©rationnel !")
    print("\n‚ú® Nouvelles fonctionnalit√©s:")
    print("- Cache intelligent avec TTL")
    print("- Analytics et m√©triques avanc√©es")
    print("- Suggestions contextuelles")
    print("- M√©moire conversationnelle")
    print("- Monitoring de performance")
    print("- Support taxes succession/entreprise")
    print("- Optimisation LLM avec post-traitement")
    print("- Export de conversation")
    print("- Configuration dynamique")
