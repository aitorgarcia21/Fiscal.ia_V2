# Configuration Railway pour LLM
# Option 1: Ollama externe (si vous avez un serveur Ollama séparé)
# LLM_ENDPOINT=https://your-ollama-server.com

# Option 2: Utiliser une API LLM externe
# OPENAI_API_KEY=your-key-here
# ANTHROPIC_API_KEY=your-key-here

# Option 3: Désactiver le LLM (utiliser uniquement le fallback regex)
LLM_ENDPOINT=disabled

# Configuration Francis Particulier
FRANCIS_USE_FALLBACK=true
FRANCIS_CACHE_ENABLED=true
FRANCIS_MAX_RESPONSE_LENGTH=5000
