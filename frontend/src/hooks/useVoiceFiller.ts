import { useState, useCallback } from 'react';
import { ClientProfile } from '../types/ClientProfile';

export function useVoiceFiller(initialProfile: Partial<ClientProfile>) {
  const [profile, setProfile] = useState<Partial<ClientProfile>>(initialProfile);
  const [suggestions, setSuggestions] = useState<string[]>([]);
  const [conversationHistory, setConversationHistory] = useState<string[]>([]);
  
  const MAX_CONTEXT_TURNS = 3; // Garde les 3 derni√®res phrases

  /**
   * üöÄ FRANCIS IA - SYST√àME D'EXTRACTION S√âMANTIQUE ULTRA-AVANC√â
   * Comprendrai TOUT avec l'IA contextuelle multi-tour !
   */

  const computeSuggestions = useCallback((currentProfile: Partial<ClientProfile>): string[] => {
    const suggestions: string[] = [];
    
    if (!currentProfile.nom_client) suggestions.push("Demandez le nom de famille");
    if (!currentProfile.prenom_client) suggestions.push("Demandez le pr√©nom");
    if (!currentProfile.situation_maritale_client) suggestions.push("Demandez la situation maritale");
    if (!currentProfile.revenu_net_annuel_client1) suggestions.push("Demandez les revenus annuels");
    
    return suggestions;
  }, []);

  /**
   * ü§ñ FRANCIS IA S√âMANTIQUE - ANALYSE CONTEXTUELLE MULTI-TOUR
   * Utilise l'historique des conversations pour une compr√©hension parfaite
   */
  const analyzeWithFrancisAI = useCallback(async (text: string, history: string[]): Promise<Partial<ClientProfile>> => {
    try {
      const contextWithHistory = history.length > 0 
        ? history.join(' | ') + ' | ' + text
        : text;
      
      console.log('üß† Francis IA analyse avec contexte:', {
        currentText: text,
        history: history,
        fullContext: contextWithHistory
      });
      
      const response = await fetch('/api/test-francis', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          question: `üß† FRANCIS - EXPERT CONTEXTUEL MULTI-TOUR ULTRA-POINTU
          
          MISSION: Analyser cette conversation avec CONTEXTE COMPLET pour extraction parfaite.
          
          CONTEXTE CONVERSATIONNEL: "${contextWithHistory}"
          PHRASE ACTUELLE: "${text}"
          
          üöÄ INTELLIGENCE CONTEXTUELLE R√âVOLUTIONNAIRE:
          ‚úÖ ANALYSE NARRATIVE: comprend le fil de l'entretien sur plusieurs phrases
          ‚úÖ RECONSTITUTION: "Je suis..." + "euh..." + "Jean Dupont" = extraction compl√®te
          ‚úÖ M√âMOIRE CONVERSATIONNELLE: utilise l'historique pour disambigu√Øser
          ‚úÖ CORRECTION CONTEXTUELLE: corrige avec l'aide du contexte pr√©c√©dent
          
          üß† INTELLIGENCE MAXIMALE REQUISE:
          Tu es le MEILLEUR LINGUISTE CONTEXTUEL au monde ! Ton travail est de comprendre
          les conversations humaines m√™me quand elles sont h√©sitantes, mal articul√©es,
          coup√©es, avec des "euh", des r√©p√©titions, des corrections, etc.
          
          üö´ REJETTE ABSOLUMENT:
          - Interjections: euh, ah, oh, hein, bon, alors, voil√†, ben
          - Questions: c'est quoi, comment, pourquoi, qu'est-ce que
          - Temporel: jour, heure, maintenant, aujourd'hui
          - Non-sens: aberrant, bizarre, wtf, expressions √©motionnelles
          - H√©sitations pures sans contenu informatif
          
          üéØ CHAMPS AUTORIS√âS:
          - nom_client: NOMS DE FAMILLE fran√ßais (m√™me d√©form√©s phon√©tiquement)
          - prenom_client: PR√âNOMS fran√ßais (m√™me mal articul√©s)
          - situation_maritale_client: "Mari√©(e)", "C√©libataire", "Divorc√©(e)", "Pacs√©(e)", "Veuf/Veuve"
          - revenu_net_annuel_client1: chiffres + mots revenus/salaire/euros
          - nombre_enfants_client: chiffres + mots enfant/gosse/petit
          - age_client: chiffres + ans/√¢ge
          - profession_client: m√©tiers/jobs (pas g√©n√©rique comme "travail")
          
          üìù EXEMPLES OBLIGATOIRES - APPRENDS CES PATTERNS :
          
          üíí STATUT MATRIMONIAL :
          "vous √™tes mari√©s" ‚Üí {"situation_maritale_client": "Mari√©(e)"}
          "nous sommes mari√©s" ‚Üí {"situation_maritale_client": "Mari√©(e)"}
          "je suis mari√©" ‚Üí {"situation_maritale_client": "Mari√©(e)"}
          "mari√©e depuis" ‚Üí {"situation_maritale_client": "Mari√©(e)"}
          "c√©libataire" ‚Üí {"situation_maritale_client": "C√©libataire"}
          "divorc√©" ‚Üí {"situation_maritale_client": "Divorc√©(e)"}
          "pacs√©" ‚Üí {"situation_maritale_client": "Pacs√©(e)"}
          
          üíº NOMS :
          Contexte: "Je suis... euh... comment dire" | Actuel: "Jean Dupont"
          ‚Üí {"prenom_client": "Jean", "nom_client": "DUPONT"}
          
          FORMAT R√âPONSE: JSON pur seulement - PAS DE TEXTE EN PLUS
          SI AUCUNE INFO FISCALE VALIDE: {}
          
          SOIS LE MEILLEUR LINGUISTE CONTEXTUEL AU MONDE ! üî•`
        })
      });

      let extractedData: Partial<ClientProfile> = {};
      
      if (response.ok) {
        const result = await response.text();
        console.log('ü§ñ Francis IA r√©ponse brute:', result);
        
        try {
          const jsonMatch = result.match(/\{[^{}]*\}/);
          if (jsonMatch) {
            extractedData = JSON.parse(jsonMatch[0]);
            console.log('üéØ Francis IA extraction r√©ussie:', extractedData);
          }
        } catch (e) {
          console.log('ü§ñ Francis IA: Pas de JSON valide dans la r√©ponse');
        }
      } else {
        console.error('Erreur API Francis:', response.status);
      }
      
      return extractedData;
    } catch (error) {
      console.error('Erreur Francis IA:', error);
      return {};
    }
  }, []);

  /**
   * Traitement d'un snippet de transcript - VERSION CONTEXTUELLE MULTI-TOUR
   */
  const handleTranscript = useCallback(
    async (text: string) => {
      if (!text) return;
      
      // üß† GESTION M√âMOIRE CONVERSATIONNELLE
      const updatedHistory = [...conversationHistory];
      
      // Ajouter la nouvelle phrase et garder seulement les N derni√®res
      updatedHistory.push(text);
      if (updatedHistory.length > MAX_CONTEXT_TURNS) {
        updatedHistory.shift(); // Supprimer la plus ancienne
      }
      
      // Mettre √† jour l'historique
      setConversationHistory(updatedHistory);
      
      console.log('üß† Francis IA analyse CONTEXTUELLE:', {
        currentText: text,
        conversationHistory: updatedHistory,
        contextDepth: updatedHistory.length
      });
      
      let updated: Partial<ClientProfile> = { ...profile };
      let matched = false;
      let matchDetails: string[] = [];

      try {
        // üß† PHASE R√âVOLUTIONNAIRE: ANALYSE CONTEXTUELLE MULTI-TOUR
        const aiExtractedData = await analyzeWithFrancisAI(text, updatedHistory);
        
        // Appliquer les donn√©es extraites par l'IA
        Object.entries(aiExtractedData).forEach(([key, value]) => {
          if (value && typeof value === 'string' && value.trim() !== '') {
            const cleanValue = value.trim();
            // Validation finale de s√©curit√©
            if (cleanValue.length >= 2 && cleanValue.length <= 50) {
              (updated as any)[key] = cleanValue;
              matched = true;
              matchDetails.push(`ü§ñ IA ${key}: ${cleanValue}`);
              console.log(`ü§ñ Francis IA a trouv√© ${key}:`, cleanValue);
            }
          }
        });

        if (matched) {
          console.log('üéØ Francis IA CONTEXTUELLE met √† jour le profil:', matchDetails);
          setProfile(updated);
          setSuggestions(computeSuggestions(updated));
        } else {
          console.log('üß† Francis IA CONTEXTUELLE: Aucune information fiscale pertinente d√©tect√©e dans ce contexte');
        }
      } catch (e) {
        console.error('Erreur Francis IA CONTEXTUELLE:', e);
      }
    },
    [profile, computeSuggestions, analyzeWithFrancisAI, conversationHistory, setConversationHistory, MAX_CONTEXT_TURNS]
  );

  return { profile, suggestions, handleTranscript };
}
