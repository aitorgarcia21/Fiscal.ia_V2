import React, { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, CheckCircle, AlertCircle, Loader2 } from 'lucide-react';

interface UltraFluidVoiceRecorderProps {
  onTranscriptionUpdate?: (text: string) => void;
  onTranscriptionComplete?: (text: string) => void;
  onError?: (error: string) => void;
  disabled?: boolean;
  className?: string;
  autoStart?: boolean;
  onListeningChange?: (isListening: boolean) => void;
  streamingMode?: boolean; // Mode streaming vers Whisper
  realTimeMode?: boolean; // Mode temps r√©el avec Web Speech API
}

export const UltraFluidVoiceRecorder: React.FC<UltraFluidVoiceRecorderProps> = ({
  onTranscriptionUpdate = () => {},
  onTranscriptionComplete = () => {},
  onError = () => {},
  disabled = false,
  className = '',
  autoStart = false,
  onListeningChange = () => {},
  streamingMode = true,
  realTimeMode = true,
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isAvailable, setIsAvailable] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [latency, setLatency] = useState(0);
  
  const recognitionRef = useRef<any>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const accumulatedTextRef = useRef<string>('');
  const isRecordingRef = useRef<boolean>(false);
  const lastResultRef = useRef<string>('');
  const streamRef = useRef<MediaStream | null>(null);
  const latencyTimerRef = useRef<number>(0);

  // Appeler onListeningChange lorsque l'√©tat d'enregistrement change
  useEffect(() => {
    onListeningChange(isRecording);
  }, [isRecording, onListeningChange]);

  // Initialisation de la reconnaissance vocale native (temps r√©el)
  useEffect(() => {
    if (!realTimeMode) return;

    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      setIsAvailable(false);
      onError('La reconnaissance vocale native n\'est pas support√©e');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognitionRef.current = new SpeechRecognition();
    
    // üöÄ PARAM√àTRES ULTRA-OPTIMIS√âS POUR LE FRAN√áAIS BUSINESS
    recognitionRef.current.continuous = true;           // √âCOUTE CONTINUE
    recognitionRef.current.interimResults = true;       // Feedback temps r√©el
    recognitionRef.current.lang = 'fr-FR';              // Fran√ßais France
    recognitionRef.current.maxAlternatives = 1;         // Une seule alternative
    
    // üéØ OPTIMISATIONS SP√âCIFIQUES FRAN√áAIS
    // Pas de grammaires sp√©cifiques - utilisation du comportement par d√©faut
    
    // üîß PARAM√àTRES DE QUALIT√â
    if ('serviceURI' in recognitionRef.current) {
      recognitionRef.current.serviceURI = undefined; // Service par d√©faut
    }
    
    console.log('üé§ Francis Voice: Configuration ultra-fluide activ√©e');

    recognitionRef.current.onerror = (event: any) => {
      console.log('üîß Francis Voice: Erreur d√©tect√©e:', event.error);
      
      // üõ°Ô∏è GESTION SIMPLE DES ERREURS
      const minorErrors = ['no-speech', 'aborted'];
      
      if (minorErrors.includes(event.error)) {
        console.log('‚ö†Ô∏è Francis Voice: Erreur mineure ignor√©e:', event.error);
        // Pas de relance automatique pour √©viter les boucles
        return;
      }
      
      // Erreur majeure - arr√™ter et signaler
      const errorMessage = `Erreur de reconnaissance: ${event.error}`;
      setError(errorMessage);
      onError(errorMessage);
      setIsRecording(false);
      isRecordingRef.current = false;
      setIsProcessing(false);
    };

    recognitionRef.current.onend = () => {
      console.log('üîÑ Francis Voice: Session termin√©e, relance automatique...');
      
      if (isRecordingRef.current) {
        // üöÄ RELANCE ULTRA-RAPIDE avec retry intelligent
        let retryCount = 0;
        const maxRetries = 3;
        
        const attemptRestart = () => {
          try {
            if (recognitionRef.current && isRecordingRef.current) {
              recognitionRef.current.start();
              console.log(`‚úÖ Francis Voice: Relance r√©ussie (tentative ${retryCount + 1})`);
            }
          } catch (error) {
            retryCount++;
            console.warn(`‚ö†Ô∏è Francis Voice: √âchec relance (tentative ${retryCount}):`, error);
            
            if (retryCount < maxRetries && isRecordingRef.current) {
              // Retry avec d√©lai progressif
              setTimeout(attemptRestart, retryCount * 200);
            } else {
              console.error('‚ùå Francis Voice: √âchec d√©finitif de relance');
              setIsRecording(false);
              isRecordingRef.current = false;
              onError('Impossible de maintenir l\'enregistrement continu');
            }
          }
        };
        
        // D√©marrer la premi√®re tentative imm√©diatement
        setTimeout(attemptRestart, 50); // D√©lai minimal pour √©viter les conflits
      }
    };

    recognitionRef.current.onresult = (event: any) => {
      const startTime = performance.now();
      
      let finalTranscript = '';
      let interimTranscript = '';
      
      // üéØ TRAITEMENT SIMPLE ET EFFICACE des r√©sultats
      for (let i = 0; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0]?.transcript?.trim() || '';
        const confidence = result[0]?.confidence || 0;
        
        if (result.isFinal && transcript.length > 0) {
          finalTranscript += transcript + ' ';
          console.log(`‚úÖ Francis Voice (FINAL): "${transcript}" | Confiance: ${(confidence * 100).toFixed(1)}%`);
        } else if (transcript.length > 0) {
          interimTranscript += transcript + ' ';
          console.log(`üéØ Francis Voice (TEMP): "${transcript}"`);
        }
      }

      // Calcul de la latence
      const endTime = performance.now();
      const currentLatency = endTime - startTime;
      setLatency(currentLatency);
      setConfidence(1.0); // Confiance fixe pour simplifier

      // üéØ MISE √Ä JOUR INTELLIGENTE - Toujours garder le texte le plus complet
      if (finalTranscript) {
        const newFinalText = finalTranscript.trim();
        accumulatedTextRef.current = (accumulatedTextRef.current + ' ' + newFinalText).trim();
        const currentText = accumulatedTextRef.current;
        lastResultRef.current = currentText;
        setCurrentTranscript(currentText);
        onTranscriptionUpdate(currentText);
        console.log(`üé§ Francis Voice: Texte accumul√© total: "${currentText}"`);
      } else if (interimTranscript) {
        const fullText = accumulatedTextRef.current + (accumulatedTextRef.current ? ' ' : '') + interimTranscript;
        lastResultRef.current = interimTranscript;
        setCurrentTranscript(fullText);
        onTranscriptionUpdate(fullText);
        // Ne pas logger les interm√©diaires pour √©viter le spam
      }
      
      // üìä STATISTIQUES DE CAPTURE
      if (finalTranscript || interimTranscript) {
        const totalLength = (accumulatedTextRef.current + ' ' + (finalTranscript || interimTranscript)).length;
        console.log(`üìä Francis Voice: Longueur totale captur√©e: ${totalLength} caract√®res`);
      }
    };

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [realTimeMode, onError, onTranscriptionUpdate, onListeningChange]);

  // Streaming vers Whisper (mode ultra-fluide)
  const streamToWhisper = useCallback(async (audioBlob: Blob) => {
    try {
      const startTime = performance.now();
      
      // Convertir en base64
      const arrayBuffer = await audioBlob.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);
      const base64Audio = btoa(String.fromCharCode.apply(null, Array.from(uint8Array)));
      
      // Envoyer √† Whisper avec optimisations
      const response = await fetch('/api/whisper/transcribe', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audio_base64: base64Audio,
          audio_format: 'webm',
          language: 'fr',
          streaming: true, // Indicateur de streaming
        }),
      });

      if (!response.ok) {
        throw new Error(`Erreur Whisper: ${response.status}`);
      }

      const result = await response.json();
      const endTime = performance.now();
      const whisperLatency = endTime - startTime;
      
      console.log(`üé§ Whisper streaming - Latence: ${whisperLatency.toFixed(0)}ms, Confiance: ${result.language_probability || 0}`);
      
      if (result.text) {
        // Fusion intelligente avec le texte natif
        const whisperText = result.text.trim();
        const nativeText = accumulatedTextRef.current;
        
        // Si le texte Whisper est plus long, l'utiliser
        if (whisperText.length > nativeText.length * 0.8) {
          accumulatedTextRef.current = whisperText;
          setCurrentTranscript(whisperText);
          onTranscriptionUpdate(whisperText);
        }
      }

      return result;
    } catch (error) {
      console.error('Erreur streaming Whisper:', error);
      onError('Erreur de transcription Whisper');
    }
  }, [onTranscriptionUpdate, onError]);

  // Initialisation du MediaRecorder pour streaming
  useEffect(() => {
    if (!streamingMode) return;

    const initMediaRecorder = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            // üöÄ PARAM√àTRES AUDIO ULTRA-OPTIMIS√âS pour capture compl√®te
            echoCancellation: true,           // Suppression √©cho
            noiseSuppression: false,          // D√âSACTIV√â pour garder toute la voix
            autoGainControl: true,            // Gain automatique
            sampleRate: 48000,                // Qualit√© maximale (48kHz au lieu de 16kHz)
            channelCount: 1,                  // Mono pour optimiser
            // Param√®tres optimis√©s pour capture compl√®te (param√®tres standards uniquement)
          } 
        });
        
        streamRef.current = stream;
        
        const mediaRecorder = new MediaRecorder(stream, {
          // üéØ CONFIGURATION ULTRA-FLUIDE MediaRecorder
          mimeType: 'audio/webm;codecs=opus',
          audioBitsPerSecond: 128000,           // Qualit√© √©lev√©e (128kbps au lieu de 16kbps)
          bitsPerSecond: 128000,                // D√©bit global √©lev√©
        });
        
        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
            
            // Streaming en temps r√©el vers Whisper
            if (streamingMode && isRecordingRef.current) {
              const audioBlob = new Blob([event.data], { type: 'audio/webm' });
              await streamToWhisper(audioBlob);
            }
          }
        };

        mediaRecorder.onstop = async () => {
          if (audioChunksRef.current.length > 0) {
            const finalBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
            await streamToWhisper(finalBlob);
          }
        };

      } catch (error) {
        console.error('Erreur initialisation MediaRecorder:', error);
        onError('Impossible d\'acc√©der au microphone');
      }
    };

    initMediaRecorder();

    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, [streamingMode, streamToWhisper, onError]);

  useEffect(() => {
    if (autoStart && isAvailable && !disabled) {
      startRecording();
    }
  }, [autoStart, isAvailable, disabled]);

  const startRecording = () => {
    if (!isAvailable || disabled) {
      setError('La reconnaissance vocale n\'est pas disponible');
      return;
    }
    
    setError(null);
    setIsProcessing(true);
    latencyTimerRef.current = performance.now();
    
    try {
      // D√©marrer la reconnaissance native
      if (realTimeMode && recognitionRef.current) {
        recognitionRef.current.start();
      }
      
      // D√©marrer le MediaRecorder pour streaming
      if (streamingMode && mediaRecorderRef.current) {
        mediaRecorderRef.current.start(1000); // Chunk toutes les secondes
      }
      
      setIsRecording(true);
      isRecordingRef.current = true;
      lastResultRef.current = '';
      setCurrentTranscript('');
      setLatency(0);
      setConfidence(0);
      
    } catch (error) {
      console.error('Erreur d√©marrage enregistrement:', error);
      const errorMsg = 'Erreur lors du d√©marrage de l\'enregistrement';
      setError(errorMsg);
      onError(errorMsg);
      setIsRecording(false);
      isRecordingRef.current = false;
      setIsProcessing(false);
    }
  };

  const stopRecording = () => {
    if (!isAvailable || !isRecording) {
      setIsProcessing(false);
      return;
    }
    
    setIsProcessing(true);
    
    try {
      // Arr√™ter la reconnaissance native
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      
      // Arr√™ter le MediaRecorder
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
      
      const finalText = accumulatedTextRef.current.trim();
      if (finalText) {
        onTranscriptionComplete(finalText);
      } else if (lastResultRef.current) {
        onTranscriptionComplete(lastResultRef.current);
      }
      
    } catch (error) {
      console.error('Erreur arr√™t enregistrement:', error);
      setError('Erreur lors de l\'arr√™t de l\'enregistrement');
    } finally {
      setIsRecording(false);
      isRecordingRef.current = false;
      setIsProcessing(false);
    }
  };

  const handleButtonClick = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  if (!isAvailable) {
    return (
      <div className={`flex items-center text-[#ef4444] ${className}`}>
        <AlertCircle className="mr-2" size={16} />
        <span className="text-sm">Reconnaissance vocale non disponible</span>
      </div>
    );
  }

  return (
    <div className="relative">
      <div className="flex items-center gap-3">

        
        <div className="flex-1">

          

        </div>
      </div>
      
      {error && (
        <div className="mt-2 text-xs text-red-400 flex items-center">
          <AlertCircle className="w-3 h-3 mr-1" /> {error}
        </div>
      )}
      
      {/* Transcription cach√©e - affichage g√©r√© par le composant parent */}
      
      {isRecording && (
        <div className="absolute -top-2 -right-2 flex items-center justify-center w-6 h-6 bg-red-500 text-white text-xs font-bold rounded-full animate-pulse">
          ‚Ä¢
        </div>
      )}
    </div>
  );
};