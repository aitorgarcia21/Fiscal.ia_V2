import React, { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, Activity } from 'lucide-react';

interface UltraSimpleLiveRecorderProps {
  onTranscription: (text: string, isFinal: boolean) => void;
  onError?: (error: string) => void;
  autoStart?: boolean;
  className?: string;
}

export const UltraSimpleLiveRecorder: React.FC<UltraSimpleLiveRecorderProps> = ({
  onTranscription,
  onError = () => {},
  autoStart = false,
  className = ''
}) => {
  const [isListening, setIsListening] = useState(false);
  const [liveText, setLiveText] = useState('');
  const [isSupported, setIsSupported] = useState(true);
  const [noiseLevel, setNoiseLevel] = useState<'low' | 'medium' | 'high'>('low');
  
  const recognitionRef = useRef<any>(null);
  const finalTranscriptRef = useRef('');
  const errorCountRef = useRef(0);
  const lastErrorTimeRef = useRef(0);
  const confidenceThresholdRef = useRef(0.3); // Seuil de confiance minimum
  
  // üéØ SETUP Web Speech API ULTRA-ROBUSTE CONTRE LE BRUIT
  useEffect(() => {
    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
    
    if (!SpeechRecognition) {
      console.error('‚ùå Web Speech API non support√©');
      setIsSupported(false);
      onError('Web Speech API non support√© sur ce navigateur');
      return;
    }
    
    const recognition = new SpeechRecognition();
    
    // üî• CONFIGURATION ULTRA-ROBUSTE CONTRE LE BRUIT
    recognition.continuous = true;        // √âCOUTE CONTINUE
    recognition.interimResults = true;    // R√âSULTATS INTERM√âDIAIRES
    recognition.lang = 'fr-FR';
    recognition.maxAlternatives = 3;      // Plus d'alternatives pour filtrer le bruit
    
    // üõ°Ô∏è PARAM√àTRES ANTI-BRUIT
    if ('webkitAudioContext' in window) {
      try {
        // R√©duire la sensibilit√© dans les environnements bruyants
        recognition.serviceURI = recognition.serviceURI || '';
      } catch (e) {
        console.log('Param√®tres audio avanc√©s non disponibles');
      }
    }
    
    // üé§ R√âSULTATS EN TEMPS R√âEL AVEC FILTRAGE ANTI-BRUIT
    recognition.onresult = (event: any) => {
      let interimTranscript = '';
      let finalTranscript = finalTranscriptRef.current;
      
      console.log('üé§ Web Speech Result Event:', event.results.length);
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        const confidence = result[0].confidence || 1;
        
        // üõ°Ô∏è FILTRAGE ANTI-BRUIT: V√©rifier confiance et longueur
        const isValidTranscript = 
          transcript.length > 2 && 
          confidence >= confidenceThresholdRef.current &&
          !transcript.match(/^[^a-zA-Z√Ä-√ø]*$/) && // Pas que des caract√®res non-alphab√©tiques
          transcript.trim().length > 0;
        
        if (!isValidTranscript) {
          console.log('üö´ BRUIT FILTR√â:', transcript, 'confidence:', confidence);
          continue;
        }
        
        // üìä AJUSTEMENT DYNAMIQUE DU SEUIL selon le bruit
        if (confidence < 0.5) {
          setNoiseLevel('high');
          confidenceThresholdRef.current = 0.6; // Plus strict
        } else if (confidence < 0.7) {
          setNoiseLevel('medium');
          confidenceThresholdRef.current = 0.4;
        } else {
          setNoiseLevel('low');
          confidenceThresholdRef.current = 0.3; // Plus permissif
        }
        
        if (result.isFinal) {
          // üî• TEXTE FINAL - Ajouter au buffer permanent
          finalTranscript += transcript + ' ';
          finalTranscriptRef.current = finalTranscript;
          
          console.log('‚úÖ FINAL:', transcript, 'confidence:', confidence);
          
          // üì° √âMISSION IMM√âDIATE vers Francis
          onTranscription(finalTranscript.trim(), false);
          setLiveText(finalTranscript.trim());
          
          // Reset compteur d'erreurs sur succ√®s
          errorCountRef.current = 0;
          
        } else {
          // ‚ö° TEXTE INTERM√âDIAIRE - Affichage live pendant que l'utilisateur parle
          interimTranscript += transcript;
          
          console.log('‚ö° INTERIM:', interimTranscript, 'confidence:', confidence);
          
          const liveDisplay = (finalTranscript + interimTranscript).trim();
          
          // üî• AFFICHAGE IMM√âDIAT - Pendant que l'utilisateur parle
          setLiveText(liveDisplay);
          onTranscription(liveDisplay, false);
        }
      }
    };
    
    // üîÑ RED√âMARRAGE AUTOMATIQUE si arr√™t inattendu
    recognition.onend = () => {
      console.log('üîÑ Recognition ended - Red√©marrage automatique...');
      if (isListening) {
        setTimeout(() => {
          try {
            recognition.start();
            console.log('‚úÖ Recognition red√©marr√©e');
          } catch (e) {
            console.error('‚ùå Erreur red√©marrage:', e);
          }
        }, 100);
      }
    };
    
    recognition.onerror = (event: any) => {
      const currentTime = Date.now();
      const timeSinceLastError = currentTime - lastErrorTimeRef.current;
      
      console.error('‚ùå Web Speech Error:', event.error, 'Count:', errorCountRef.current);
      
      // üõ°Ô∏è GESTION INTELLIGENTE DES ERREURS DE BRUIT
      if (event.error === 'no-speech') {
        // Pas d'erreur, juste silence
        console.log('üîá Silence d√©tect√© - Normal');
        return;
      }
      
      if (event.error === 'audio-capture') {
        errorCountRef.current++;
        
        if (errorCountRef.current < 3 && timeSinceLastError > 2000) {
          console.log('üîÑ Erreur audio - Tentative de red√©marrage...');
          setTimeout(() => {
            if (isListening && recognitionRef.current) {
              try {
                recognitionRef.current.start();
              } catch (e) {
                console.log('Red√©marrage apr√®s erreur audio √©chou√©');
              }
            }
          }, 500);
        }
      }
      
      if (event.error === 'network') {
        setNoiseLevel('high');
        confidenceThresholdRef.current = 0.7; // Plus strict en cas de probl√®me r√©seau
      }
      
      lastErrorTimeRef.current = currentTime;
      
      // Ne signaler que les vraies erreurs critiques
      if (event.error !== 'no-speech' && event.error !== 'aborted' && 
          event.error !== 'audio-capture' && errorCountRef.current > 2) {
        onError(`Erreur recognition: ${event.error}`);
      }
    };
    
    recognition.onstart = () => {
      console.log('üé§ Recognition d√©marr√©e');
    };
    
    recognitionRef.current = recognition;
    
  }, [isListening, onTranscription, onError]);
  
  // üéØ D√âMARRER L'√âCOUTE
  const startListening = useCallback(() => {
    if (!recognitionRef.current || !isSupported) return;
    
    try {
      setIsListening(true);
      setLiveText('');
      finalTranscriptRef.current = '';
      
      recognitionRef.current.start();
      console.log('üöÄ √âcoute continue d√©marr√©e');
      
    } catch (error) {
      console.error('‚ùå Erreur start:', error);
      onError(`Erreur d√©marrage: ${error}`);
      setIsListening(false);
    }
  }, [isSupported, onError]);
  
  // üõë ARR√äTER L'√âCOUTE
  const stopListening = useCallback(() => {
    if (!recognitionRef.current) return;
    
    try {
      setIsListening(false);
      recognitionRef.current.stop();
      
      // √âmission finale
      if (finalTranscriptRef.current.trim()) {
        onTranscription(finalTranscriptRef.current.trim(), true);
      }
      
      console.log('üõë √âcoute arr√™t√©e');
      
    } catch (error) {
      console.error('‚ùå Erreur stop:', error);
    }
  }, [onTranscription]);
  
  // Toggle
  const toggleListening = () => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  };
  
  // Auto-start
  useEffect(() => {
    if (autoStart && !isListening && isSupported) {
      startListening();
    }
  }, [autoStart, isListening, isSupported, startListening]);
  
  // Nettoyage
  useEffect(() => {
    return () => {
      if (recognitionRef.current && isListening) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          console.log('Cleanup recognition stop error:', e);
        }
      }
    };
  }, [isListening]);
  
  if (!isSupported) {
    return (
      <div className="text-red-400 p-4 rounded-lg border border-red-500/20">
        ‚ùå Web Speech API non support√© sur ce navigateur
      </div>
    );
  }
  
  return (
    <div className={`space-y-4 ${className}`}>
      {/* Bouton principal */}
      <div className="flex items-center space-x-4">
        <button
          onClick={toggleListening}
          className={`
            relative flex items-center justify-center w-16 h-16 rounded-full
            transition-all duration-300 focus:outline-none focus:ring-4
            ${isListening 
              ? 'bg-red-600 hover:bg-red-700 text-white shadow-lg shadow-red-500/30 focus:ring-red-500/50 animate-pulse' 
              : 'bg-gradient-to-r from-[#c5a572] to-[#e8cfa0] hover:from-[#e8cfa0] hover:to-[#c5a572] text-[#162238] shadow-lg shadow-[#c5a572]/30 focus:ring-[#c5a572]/50'
            }
            hover:scale-105 cursor-pointer
          `}
          aria-label={isListening ? 'Arr√™ter l\'√©coute' : 'D√©marrer l\'√©coute'}
        >
          {isListening ? (
            <MicOff className="w-8 h-8" />
          ) : (
            <Mic className="w-8 h-8" />
          )}
          
          {/* Indicateur d'activit√© */}
          {isListening && (
            <div className="absolute -top-2 -right-2">
              <Activity className="w-6 h-6 text-white animate-bounce" />
            </div>
          )}
        </button>
        
        <div className="flex-1">
          <div className="flex items-center space-x-2 mb-2">
            <div className={`w-4 h-4 rounded-full transition-colors duration-300 ${
              isListening ? 'bg-green-500 animate-pulse' : 'bg-gray-500'
            }`} />
            <span className={`font-medium ${
              isListening ? 'text-green-400' : 'text-gray-400'
            }`}>
              {isListening ? '√âCOUTE LIVE ACTIVE' : 'Pr√™t √† √©couter'}
            </span>
            {isListening && (
              <span className="text-green-400 font-bold text-sm animate-pulse">‚óè LIVE</span>
            )}
            
            {/* üõ°Ô∏è INDICATEUR NIVEAU DE BRUIT */}
            {isListening && (
              <div className={`px-2 py-1 rounded text-xs font-medium ${
                noiseLevel === 'low' ? 'bg-green-500/20 text-green-400' :
                noiseLevel === 'medium' ? 'bg-yellow-500/20 text-yellow-400' :
                'bg-red-500/20 text-red-400'
              }`}>
                {noiseLevel === 'low' ? 'üîá Calme' :
                 noiseLevel === 'medium' ? 'üîä Bruit mod√©r√©' :
                 'üö® Environnement bruyant'}
              </div>
            )}
          </div>
          
          <div className="text-sm text-gray-400">
            Web Speech API ‚Ä¢ Fran√ßais ‚Ä¢ Anti-Bruit ‚Ä¢ Temps R√©el
          </div>
        </div>
      </div>
      
      {/* Affichage du texte LIVE */}
      <div className="min-h-[100px] bg-gradient-to-br from-[#0A192F] to-[#162238] rounded-xl border border-[#c5a572]/20 p-4 relative">
        {liveText ? (
          <div className="space-y-2">
            <div className="text-gray-200 text-base leading-relaxed">
              {liveText}
              {isListening && (
                <span className="inline-block w-1 h-5 bg-green-400 ml-1 animate-ping" />
              )}
            </div>
            
            <div className="flex justify-between items-center pt-2 border-t border-[#c5a572]/10">
              <span className="text-xs text-gray-500">
                {liveText.split(' ').length} mots
              </span>
              <span className="text-xs text-green-400 font-medium">
                ‚ö° TRANSCRIPTION LIVE
              </span>
            </div>
          </div>
        ) : (
          <div className="flex items-center justify-center h-full text-center">
            <div className="space-y-2">
              <Mic className={`w-12 h-12 mx-auto ${
                isListening ? 'text-green-400 animate-pulse' : 'text-gray-500'
              }`} />
              <p className={`font-medium ${
                isListening ? 'text-green-400' : 'text-gray-400'
              }`}>
                {isListening ? 'üé§ J\'√âCOUTE... PARLEZ MAINTENANT !' : 'üé§ Cliquez pour activer'}
              </p>
              {isListening && (
                <p className="text-green-300 text-sm animate-pulse">
                  Le texte appara√Ætra ici EN TEMPS R√âEL
                </p>
              )}
            </div>
          </div>
        )}
        
        {/* Effet visuel d'√©coute */}
        {isListening && (
          <div className="absolute inset-0 pointer-events-none">
            <div className="absolute top-0 left-0 w-full h-1 bg-gradient-to-r from-green-400/0 via-green-400/80 to-green-400/0 animate-pulse" />
            <div className="absolute bottom-0 left-0 w-full h-1 bg-gradient-to-r from-[#c5a572]/0 via-[#c5a572]/80 to-[#c5a572]/0 animate-pulse" 
                 style={{ animationDelay: '0.5s' }} />
          </div>
        )}
      </div>
    </div>
  );
};

export default UltraSimpleLiveRecorder;
